# app.py - API –¥–ª—è Railway + n8n —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ JSON –¥–∞–Ω–Ω—ã–º–∏
import os
import pickle
import pandas as pd
import numpy as np
import re
from flask import Flask, request, jsonify
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –º–æ–¥–µ–ª–∏
model_artifacts = None

def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    global model_artifacts
    try:
        model_file = 'solana_token_xgboost_model.pkl'
        if os.path.exists(model_file):
            with open(model_file, 'rb') as f:
                model_artifacts = pickle.load(f)
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞! AUC: {model_artifacts['performance_metrics']['test_auc']:.4f}")
            return True
        else:
            logger.error(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ {model_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return False

def parse_value_with_suffix(value_str):
    """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏ K, M, B"""
    if not value_str or value_str is None:
        return 0
    
    if isinstance(value_str, (int, float)):
        return float(value_str)
    
    value_str = str(value_str).replace(',', '').replace('
import os
import pickle
import pandas as pd
import numpy as np
import re
from flask import Flask, request, jsonify
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –º–æ–¥–µ–ª–∏
model_artifacts = None

def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    global model_artifacts
    try:
        model_file = 'solana_token_xgboost_model.pkl'
        if os.path.exists(model_file):
            with open(model_file, 'rb') as f:
                model_artifacts = pickle.load(f)
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞! AUC: {model_artifacts['performance_metrics']['test_auc']:.4f}")
            return True
        else:
            logger.error(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ {model_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return False

def parse_token_data(cena_full_text):
    """–ü–∞—Ä—Å–∏—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
    
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–º–≤–æ–ª —Ç–æ–∫–µ–Ω–∞
        symbol_match = re.search(r'\$([A-Z0-9]+)', cena_full_text)
        symbol = symbol_match.group(1) if symbol_match else "UNKNOWN"
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–æ–∑—Ä–∞—Å—Ç —Ç–æ–∫–µ–Ω–∞ (–≤ –º–∏–Ω—É—Ç–∞—Ö)
        age_match = re.search(r'Token age:\s*(\d+)m', cena_full_text)
        token_age_minutes = int(age_match.group(1)) if age_match else 0
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        mc_match = re.search(r'MC: \$([0-9,\.]+)K', cena_full_text)
        market_cap = float(mc_match.group(1).replace(',', '')) * 1000 if mc_match else 0
        
        liq_match = re.search(r'Liq: \$([0-9,\.]+)K', cena_full_text)
        liquidity = float(liq_match.group(1).replace(',', '')) * 1000 if liq_match else 0
        
        # SOL pooled
        sol_match = re.search(r'SOL pooled: ([0-9,\.]+)', cena_full_text)
        sol_pooled = float(sol_match.group(1).replace(',', '')) if sol_match else 0
        
        # ATH
        ath_match = re.search(r'ATH: \$([0-9,\.]+)K', cena_full_text)
        ath = float(ath_match.group(1).replace(',', '')) * 1000 if ath_match else 0
        
        # –û–±—ä–µ–º—ã 1 –º–∏–Ω—É—Ç–∞
        vol_1m_match = re.search(r'Volume: \$([0-9,\.]+)', cena_full_text)
        volume_1m = float(vol_1m_match.group(1).replace(',', '')) if vol_1m_match else 0
        
        buy_vol_1m_match = re.search(r'Buy volume \(\$\): \$([0-9,\.]+)', cena_full_text)
        buy_volume_1m = float(buy_vol_1m_match.group(1).replace(',', '')) if buy_vol_1m_match else 0
        
        sell_vol_1m_match = re.search(r'Sell volume \(\$\): \$([0-9,\.]+)', cena_full_text)
        sell_volume_1m = float(sell_vol_1m_match.group(1).replace(',', '')) if sell_vol_1m_match else 0
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∫—É–ø–æ–∫/–ø—Ä–æ–¥–∞–∂
        buys_1m_match = re.search(r'Buys: (\d+)', cena_full_text)
        buys_1m = int(buys_1m_match.group(1)) if buys_1m_match else 0
        
        sells_1m_match = re.search(r'Sells: (\d+)', cena_full_text)
        sells_1m = int(sells_1m_match.group(1)) if sells_1m_match else 0
        
        # –û–±—ä–µ–º—ã 5 –º–∏–Ω—É—Ç (–∏—â–µ–º –≤—Ç–æ—Ä—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
        vol_5m_matches = re.findall(r'Volume: \$([0-9,\.]+)', cena_full_text)
        volume_5m = float(vol_5m_matches[1].replace(',', '')) if len(vol_5m_matches) > 1 else 0
        
        buy_vol_5m_matches = re.findall(r'Buy volume \(\$\): \$([0-9,\.]+)', cena_full_text)
        buy_volume_5m = float(buy_vol_5m_matches[1].replace(',', '')) if len(buy_vol_5m_matches) > 1 else 0
        
        sell_vol_5m_matches = re.findall(r'Sell volume \(\$\): \$([0-9,\.]+)', cena_full_text)
        sell_volume_5m = float(sell_vol_5m_matches[1].replace(',', '')) if len(sell_vol_5m_matches) > 1 else 0
        
        buys_5m_matches = re.findall(r'Buys: (\d+)', cena_full_text)
        buys_5m = int(buys_5m_matches[1]) if len(buys_5m_matches) > 1 else 0
        
        sells_5m_matches = re.findall(r'Sells: (\d+)', cena_full_text)
        sells_5m = int(sells_5m_matches[1]) if len(sells_5m_matches) > 1 else 0
        
        # –ü–æ–∫—É–ø–∞—Ç–µ–ª–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        green_match = re.search(r'üü¢: (\d+)', cena_full_text)
        buyers_green = int(green_match.group(1)) if green_match else 0
        
        blue_match = re.search(r'üîµ: (\d+)', cena_full_text)
        buyers_blue = int(blue_match.group(1)) if blue_match else 0
        
        yellow_match = re.search(r'üü°: (\d+)', cena_full_text)
        buyers_yellow = int(yellow_match.group(1)) if yellow_match else 0
        
        red_match = re.search(r'‚≠ïÔ∏è: (\d+)', cena_full_text)
        buyers_red = int(red_match.group(1)) if red_match else 0
        
        # –°–Ω–∞–π–ø–µ—Ä—ã
        clown_match = re.search(r'ü§°: (\d+)', cena_full_text)
        buyers_clown = int(clown_match.group(1)) if clown_match else 0
        
        sun_match = re.search(r'üåû: (\d+)', cena_full_text)
        buyers_sun = int(sun_match.group(1)) if sun_match else 0
        
        moon_half_match = re.search(r'üåó: (\d+)', cena_full_text)
        buyers_moon_half = int(moon_half_match.group(1)) if moon_half_match else 0
        
        moon_new_match = re.search(r'üåö: (\d+)', cena_full_text)
        buyers_moon_new = int(moon_new_match.group(1)) if moon_new_match else 0
        
        # Current/Initial ratio
        ratio_match = re.search(r'Current/Initial: ([0-9\.]+)% / ([0-9\.]+)%', cena_full_text)
        current_ratio = float(ratio_match.group(1)) if ratio_match else 0
        initial_ratio = float(ratio_match.group(2)) if ratio_match else 0
        
        # –î–µ—Ä–∂–∞—Ç–µ–ª–∏
        total_holders_match = re.search(r'Total: (\d+)', cena_full_text)
        total_holders = int(total_holders_match.group(1)) if total_holders_match else 0
        
        freshies_1d_match = re.search(r'Freshies: ([0-9\.]+)% 1D', cena_full_text)
        freshies_1d_percent = float(freshies_1d_match.group(1)) if freshies_1d_match else 0
        
        freshies_7d_match = re.search(r'([0-9\.]+)% 7D', cena_full_text)
        freshies_7d_percent = float(freshies_7d_match.group(1)) if freshies_7d_match else 0
        
        top_10_match = re.search(r'Top 10: (\d+)%', cena_full_text)
        top_10_percent = float(top_10_match.group(1)) if top_10_match else 0
        
        # Top 10 holdings - –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        holdings_match = re.search(r'Top 10 Holding.*?\n([0-9\.]+)', cena_full_text, re.DOTALL)
        top_10_holdings = float(holdings_match.group(1)) if holdings_match else 0
        
        # Dev –¥–∞–Ω–Ω—ã–µ
        dev_balance_match = re.search(r'Dev current balance: (\d+)%', cena_full_text)
        dev_current_balance_percent = float(dev_balance_match.group(1)) if dev_balance_match else 0
        
        dev_sol_match = re.search(r'Dev SOL balance: ([0-9\.]+) SOL', cena_full_text)
        dev_sol_balance = float(dev_sol_match.group(1)) if dev_sol_match else 0
        
        # Security flags (üü¢ = 1, üî¥ = 0)
        security_no_mint = 1 if '‚îú NoMint: üü¢' in cena_full_text else 0
        security_blacklist = 1 if '‚îú Blacklist: üü¢' in cena_full_text else 0
        security_burnt = 1 if '‚îú Burnt: üü¢' in cena_full_text else 0
        security_dev_sold = 1 if '‚îú Dev Sold: üü¢' in cena_full_text else 0
        security_dex_paid = 1 if '‚îî Dex Paid: üü¢' in cena_full_text else 0
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        parsed_data = {
            'symbol': symbol,
            'token_age_minutes': token_age_minutes,
            'market_cap': market_cap,
            'liquidity': liquidity,
            'sol_pooled': sol_pooled,
            'ath': ath,
            'volume_1m': volume_1m,
            'buy_volume_1m': buy_volume_1m,
            'sell_volume_1m': sell_volume_1m,
            'buys_1m': buys_1m,
            'sells_1m': sells_1m,
            'volume_5m': volume_5m,
            'buy_volume_5m': buy_volume_5m,
            'sell_volume_5m': sell_volume_5m,
            'buys_5m': buys_5m,
            'sells_5m': sells_5m,
            'buyers_green': buyers_green,
            'buyers_blue': buyers_blue,
            'buyers_yellow': buyers_yellow,
            'buyers_red': buyers_red,
            'buyers_clown': buyers_clown,
            'buyers_sun': buyers_sun,
            'buyers_moon_half': buyers_moon_half,
            'buyers_moon_new': buyers_moon_new,
            'current_ratio': current_ratio,
            'initial_ratio': initial_ratio,
            'total_holders': total_holders,
            'freshies_1d_percent': freshies_1d_percent,
            'freshies_7d_percent': freshies_7d_percent,
            'top_10_percent': top_10_percent,
            'top_10_holdings': top_10_holdings,
            'dev_current_balance_percent': dev_current_balance_percent,
            'dev_sol_balance': dev_sol_balance,
            'security_no_mint': security_no_mint,
            'security_blacklist': security_blacklist,
            'security_burnt': security_burnt,
            'security_dev_sold': security_dev_sold,
            'security_dex_paid': security_dex_paid
        }
        
        logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–µ–Ω –¥–ª—è {symbol}: MC=${market_cap:,.0f}, Liq=${liquidity:,.0f}")
        return parsed_data
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞: {e}")

def predict_token_success(token_data):
    """–§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–∞"""
    
    if model_artifacts is None:
        raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    try:
        # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        df_new = pd.DataFrame([token_data])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        for col in model_artifacts['feature_names']:
            if col not in df_new.columns:
                df_new[col] = 0
        
        # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
        df_new = df_new[model_artifacts['feature_names']]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–º–ø—É—Ç–µ—Ä
        df_imputed = pd.DataFrame(
            model_artifacts['imputer'].transform(df_new), 
            columns=model_artifacts['feature_names']
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è (Railway)
    port = int(os.environ.get('PORT', 5000))
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    app.run(host='0.0.0.0', port=port, debug=False)–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        prediction = model_artifacts['model'].predict(df_imputed)[0]
        probability = model_artifacts['model'].predict_proba(df_imputed)[0, 1]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        confidence_score = abs(probability - 0.5) * 2
        if confidence_score > 0.8:
            confidence_level = "very_high"
        elif confidence_score > 0.6:
            confidence_level = "high"
        elif confidence_score > 0.4:
            confidence_level = "medium"
        else:
            confidence_level = "low"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'prediction': 'success' if prediction == 1 else 'fail',
            'binary_prediction': int(prediction),
            'probability': round(probability, 4),
            'probability_percent': round(probability * 100, 1),
            'confidence_score': round(confidence_score, 4),
            'confidence_level': confidence_level,
            'expected_pnl': 'PNL >= 2x' if prediction == 1 else 'PNL < 2x'
        }
        
        return result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        raise

def analyze_token_signals(token_data):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∏–≥–Ω–∞–ª—ã —Ç–æ–∫–µ–Ω–∞"""
    
    # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã (—Ö–æ–ª–¥—è—Ç –∏ –¥–æ–∫—É–ø–∞—é—Ç)
    positive = (token_data.get('buyers_green', 0) + 
                token_data.get('buyers_blue', 0) + 
                token_data.get('buyers_clown', 0) + 
                token_data.get('buyers_sun', 0))
    
    # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã (–ø—Ä–æ–¥–∞–ª–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é)
    negative = (token_data.get('buyers_red', 0) + 
                token_data.get('buyers_moon_new', 0))
    
    # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ
    ratio = positive / (negative + 1)
    
    if ratio > 3:
        status = "very_good"
    elif ratio > 1.5:
        status = "good"
    elif ratio > 0.8:
        status = "medium"
    else:
        status = "bad"
    
    return {
        'positive_signals': positive,
        'negative_signals': negative,
        'signal_ratio': round(ratio, 2),
        'signal_status': status
    }

def check_token_safety(token_data):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞"""
    
    safety_score = 0
    issues = []
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—é
    top10 = token_data.get('top_10_percent', 0)
    if top10 <= 70:
        safety_score += 1
    else:
        issues.append(f"high_concentration_{top10}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
    dev_percent = token_data.get('dev_current_balance_percent', 0)
    if dev_percent <= 20:
        safety_score += 1
    else:
        issues.append(f"dev_holds_much_{dev_percent}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
    liquidity = token_data.get('liquidity', 0)
    if liquidity >= 100000:
        safety_score += 1
    else:
        issues.append(f"low_liquidity_{liquidity}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
    if token_data.get('security_no_mint', 0):
        safety_score += 1
    else:
        issues.append("mint_not_disabled")
        
    if token_data.get('security_burnt', 0):
        safety_score += 1
    else:
        issues.append("tokens_not_burnt")
    
    return {
        'safety_score': safety_score,
        'max_safety_score': 5,
        'safety_percentage': round((safety_score / 5) * 100),
        'safety_issues': issues,
        'is_safe': safety_score >= 3
    }

def get_recommendation(prediction_result, signals, safety):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é"""
    
    probability = prediction_result['probability']
    safety_score = safety['safety_score']
    
    if probability >= 0.7 and safety_score >= 4:
        return {
            'recommendation': 'BUY',
            'risk_level': 'low',
            'reason': 'excellent_token'
        }
    elif probability >= 0.6 and safety_score >= 3:
        return {
            'recommendation': 'CONSIDER',
            'risk_level': 'medium',
            'reason': 'good_potential'
        }
    elif probability >= 0.5 and safety_score >= 2:
        return {
            'recommendation': 'CAUTION',
            'risk_level': 'medium_high',
            'reason': 'moderate_risk'
        }
    else:
        return {
            'recommendation': 'AVOID',
            'risk_level': 'high',
            'reason': 'high_risk'
        }

# =============================================================================
# API ENDPOINTS
# =============================================================================

@app.route('/', methods=['GET'])
def home():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ API"""
    return jsonify({
        'service': 'Solana Token Predictor API',
        'status': 'online',
        'model_loaded': model_artifacts is not None,
        'endpoints': {
            'predict': '/predict [POST]',
            'predict_text': '/predict-text [POST]',
            'health': '/health [GET]',
            'model_info': '/model-info [GET]'
        }
    })

@app.route('/predict-text', methods=['POST'])
def predict_text():
    """Endpoint –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–æ—Å–Ω–æ–≤–Ω–æ–π –¥–ª—è n8n)"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Content-Type must be application/json'
            }), 400
        
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        # –û–∂–∏–¥–∞–µ–º –ø–æ–ª–µ cena_full —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        cena_full_text = data.get('cena_full')
        if not cena_full_text:
            return jsonify({
                'success': False,
                'error': 'Field "cena_full" is required'
            }), 400
        
        # –ü–∞—Ä—Å–∏–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        parsed_token_data = parse_token_data(cena_full_text)
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prediction_result = predict_token_success(parsed_token_data)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
        signals = analyze_token_signals(parsed_token_data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        safety = check_token_safety(parsed_token_data)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
        recommendation = get_recommendation(prediction_result, signals, safety)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = {
            'success': True,
            'token_symbol': parsed_token_data.get('symbol', 'UNKNOWN'),
            'parsed_data': parsed_token_data,
            'prediction': prediction_result,
            'signals': signals,
            'safety': safety,
            'recommendation': recommendation,
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        logger.info(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {parsed_token_data.get('symbol', 'UNKNOWN')} -> {prediction_result['prediction']} ({prediction_result['probability_percent']}%)")
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/predict', methods=['POST'])
def predict():
    """Endpoint –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Content-Type must be application/json'
            }), 400
        
        token_data = request.get_json()
        
        if not token_data:
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prediction_result = predict_token_success(token_data)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
        signals = analyze_token_signals(token_data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        safety = check_token_safety(token_data)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
        recommendation = get_recommendation(prediction_result, signals, safety)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = {
            'success': True,
            'token_symbol': token_data.get('symbol', 'UNKNOWN'),
            'prediction': prediction_result,
            'signals': signals,
            'safety': safety,
            'recommendation': recommendation,
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        logger.info(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {token_data.get('symbol', 'UNKNOWN')} -> {prediction_result['prediction']} ({prediction_result['probability_percent']}%)")
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/health', methods=['GET'])
def health():
    """Health check –¥–ª—è Railway"""
    
    model_info = {}
    if model_artifacts:
        model_info = {
            'auc': model_artifacts['performance_metrics']['test_auc'],
            'f1': model_artifacts['performance_metrics']['test_f1'],
            'features_count': len(model_artifacts['feature_names'])
        }
    
    return jsonify({
        'status': 'healthy',
        'model_loaded': model_artifacts is not None,
        'model_info': model_info,
        'timestamp': pd.Timestamp.now().isoformat()
    })

@app.route('/model-info', methods=['GET'])
def model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    # –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    top_features = model_artifacts['feature_importance'].head(10).to_dict('records')
    
    return jsonify({
        'success': True,
        'model_type': model_artifacts.get('model_type', 'Unknown'),
        'training_approach': model_artifacts.get('training_approach', 'Unknown'),
        'performance_metrics': model_artifacts['performance_metrics'],
        'features_count': len(model_artifacts['feature_names']),
        'top_features': top_features,
        'all_features': model_artifacts['feature_names']
    })

@app.route('/example-text', methods=['GET'])
def example_text():
    """–ü—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
    
    example_data = {
        "cena_full": "üé≤ $CRUMB | Crumbcat\nHz7MeU72BNF9rCWyUFAwKTyCcjr6qsJm1jwYehnqjups\n‚è≥ Token age:  2m  | üëÅ 59\n‚îú MC: $129.1K\n‚îú Liq: $47.3K / SOL pooled: --\n‚îî ATH: $152.7K (-21% / 32s)\n1 min:\n‚îú Volume: $148,947.33\n‚îú Buy volume ($): $81,396.06\n‚îú Sell volume ($): $67,551.28\n‚îú Buys: 567\n‚îî Sells: 453\n5 min:\n‚îú Volume: $172,794.94\n‚îú Buy volume ($): $98,494.49\n‚îú Sell volume ($): $74,300.45\n‚îú Buys: 670\n‚îî Sells: 517\nüéØ First 70 buyers:\n‚≠ïÔ∏è‚≠ïÔ∏è‚≠ïÔ∏è‚≠ïÔ∏èüü°‚≠ïÔ∏èüîµ‚≠ïÔ∏è‚≠ïÔ∏èüü°\nüü°üü°‚≠ïÔ∏èüü°‚≠ïÔ∏èüü°‚≠ïÔ∏è‚≠ïÔ∏è‚≠ïÔ∏è‚≠ïÔ∏è\n‚≠ïÔ∏èüü°üü°‚≠ïÔ∏èüü¢üü°üü°‚≠ïÔ∏è‚≠ïÔ∏è‚≠ïÔ∏è\nüü°üü°üü¢üü¢‚≠ïÔ∏èüü°üü°üü¢üü°üü°\nüü°‚≠ïÔ∏èüü°üü°üü¢üü¢üü¢‚≠ïÔ∏è‚≠ïÔ∏èüü°\nüü¢üü°‚≠ïÔ∏èüü°üü°üü¢üü°üîµüü°‚≠ïÔ∏è\n‚≠ïÔ∏èüü¢üü°üü¢‚≠ïÔ∏è‚≠ïÔ∏èüü¢üü¢üü¢üü°\n‚îú üü¢: 14 | üîµ: 2 | üü°: 27 | ‚≠ïÔ∏è: 27\n‚îú ü§°: 0 | üåû: 0 | üåó: 0 | üåö: 0\n‚îú Current/Initial: 23.8% / 72.58%\nüë• Holders:\n‚îú Total: 383\n‚îú Freshies: 5.5% 1D | 18% 7D\n‚îú Top 10: 21%\nüí∞ Top 10 Holding (%)\n29.2 | 3.38 | 3.32 | 2.96 | 2.95 | 2.56 | 2.49 | 2.26 | 1.95 | 1.89\nüòé Dev\n‚îú Dev current balance: 0%\n‚îî Dev SOL balance: 0.225 SOL\nüîí Security:\n‚îú NoMint: üü¢\n‚îú Blacklist: üü¢\n‚îú Burnt: üü¢\n‚îú Dev Sold: üü¢\n‚îî Dex Paid: üî¥"
    }
    
    return jsonify({
        'example_request': {
            'url': request.base_url.replace('/example-text', '/predict-text'),
            'method': 'POST',
            'headers': {
                'Content-Type': 'application/json'
            },
            'body': example_data
        },
        'required_fields': [
            'cena_full (string with full token data)'
        ],
        'note': 'Send the complete text data in cena_full field'
    })

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'success': False,
        'error': 'Endpoint not found',
        'available_endpoints': ['/predict-text', '/predict', '/health', '/model-info', '/example-text']
    }), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'success': False,
        'error': 'Internal server error'
    }), 500

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == '__main__':
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    load_model()
    
    # –ü–æ–ª—É—á# app.py - –ü—Ä–æ—Å—Ç–æ–π API –¥–ª—è Railway + n8n
import os
import pickle
import pandas as pd
import numpy as np
from flask import Flask, request, jsonify
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –º–æ–¥–µ–ª–∏
model_artifacts = None

def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    global model_artifacts
    try:
        model_file = 'solana_token_xgboost_model.pkl'
        if os.path.exists(model_file):
            with open(model_file, 'rb') as f:
                model_artifacts = pickle.load(f)
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞! AUC: {model_artifacts['performance_metrics']['test_auc']:.4f}")
            return True
        else:
            logger.error(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ {model_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return False

def predict_token_success(token_data):
    """–§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–∞"""
    
    if model_artifacts is None:
        raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    try:
        # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        df_new = pd.DataFrame([token_data])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        for col in model_artifacts['feature_names']:
            if col not in df_new.columns:
                df_new[col] = 0
        
        # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
        df_new = df_new[model_artifacts['feature_names']]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–º–ø—É—Ç–µ—Ä
        df_imputed = pd.DataFrame(
            model_artifacts['imputer'].transform(df_new), 
            columns=model_artifacts['feature_names']
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        prediction = model_artifacts['model'].predict(df_imputed)[0]
        probability = model_artifacts['model'].predict_proba(df_imputed)[0, 1]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        confidence_score = abs(probability - 0.5) * 2
        if confidence_score > 0.8:
            confidence_level = "very_high"
        elif confidence_score > 0.6:
            confidence_level = "high"
        elif confidence_score > 0.4:
            confidence_level = "medium"
        else:
            confidence_level = "low"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'prediction': 'success' if prediction == 1 else 'fail',
            'binary_prediction': int(prediction),
            'probability': round(probability, 4),
            'probability_percent': round(probability * 100, 1),
            'confidence_score': round(confidence_score, 4),
            'confidence_level': confidence_level,
            'expected_pnl': 'PNL >= 2x' if prediction == 1 else 'PNL < 2x'
        }
        
        return result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        raise

def analyze_token_signals(token_data):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∏–≥–Ω–∞–ª—ã —Ç–æ–∫–µ–Ω–∞"""
    
    # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã (—Ö–æ–ª–¥—è—Ç –∏ –¥–æ–∫—É–ø–∞—é—Ç)
    positive = (token_data.get('buyers_green', 0) + 
                token_data.get('buyers_blue', 0) + 
                token_data.get('buyers_clown', 0) + 
                token_data.get('buyers_sun', 0))
    
    # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã (–ø—Ä–æ–¥–∞–ª–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é)
    negative = (token_data.get('buyers_red', 0) + 
                token_data.get('buyers_moon_new', 0))
    
    # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ
    ratio = positive / (negative + 1)
    
    if ratio > 3:
        status = "very_good"
    elif ratio > 1.5:
        status = "good"
    elif ratio > 0.8:
        status = "medium"
    else:
        status = "bad"
    
    return {
        'positive_signals': positive,
        'negative_signals': negative,
        'signal_ratio': round(ratio, 2),
        'signal_status': status
    }

def check_token_safety(token_data):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞"""
    
    safety_score = 0
    issues = []
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—é
    top10 = token_data.get('top_10_percent', 0)
    if top10 <= 70:
        safety_score += 1
    else:
        issues.append(f"high_concentration_{top10}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
    dev_percent = token_data.get('dev_current_balance_percent', 0)
    if dev_percent <= 20:
        safety_score += 1
    else:
        issues.append(f"dev_holds_much_{dev_percent}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
    liquidity = token_data.get('liquidity', 0)
    if liquidity >= 100000:
        safety_score += 1
    else:
        issues.append(f"low_liquidity_{liquidity}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
    if token_data.get('security_no_mint', 0):
        safety_score += 1
    else:
        issues.append("mint_not_disabled")
        
    if token_data.get('security_burnt', 0):
        safety_score += 1
    else:
        issues.append("tokens_not_burnt")
    
    return {
        'safety_score': safety_score,
        'max_safety_score': 5,
        'safety_percentage': round((safety_score / 5) * 100),
        'safety_issues': issues,
        'is_safe': safety_score >= 3
    }

def get_recommendation(prediction_result, signals, safety):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é"""
    
    probability = prediction_result['probability']
    safety_score = safety['safety_score']
    
    if probability >= 0.7 and safety_score >= 4:
        return {
            'recommendation': 'BUY',
            'risk_level': 'low',
            'reason': 'excellent_token'
        }
    elif probability >= 0.6 and safety_score >= 3:
        return {
            'recommendation': 'CONSIDER',
            'risk_level': 'medium',
            'reason': 'good_potential'
        }
    elif probability >= 0.5 and safety_score >= 2:
        return {
            'recommendation': 'CAUTION',
            'risk_level': 'medium_high',
            'reason': 'moderate_risk'
        }
    else:
        return {
            'recommendation': 'AVOID',
            'risk_level': 'high',
            'reason': 'high_risk'
        }

# =============================================================================
# API ENDPOINTS
# =============================================================================

@app.route('/', methods=['GET'])
def home():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ API"""
    return jsonify({
        'service': 'Solana Token Predictor API',
        'status': 'online',
        'model_loaded': model_artifacts is not None,
        'endpoints': {
            'predict': '/predict [POST]',
            'health': '/health [GET]',
            'model_info': '/model-info [GET]'
        }
    })

@app.route('/predict', methods=['POST'])
def predict():
    """–û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Content-Type must be application/json'
            }), 400
        
        token_data = request.get_json()
        
        if not token_data:
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prediction_result = predict_token_success(token_data)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
        signals = analyze_token_signals(token_data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        safety = check_token_safety(token_data)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
        recommendation = get_recommendation(prediction_result, signals, safety)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = {
            'success': True,
            'token_symbol': token_data.get('symbol', 'UNKNOWN'),
            'prediction': prediction_result,
            'signals': signals,
            'safety': safety,
            'recommendation': recommendation,
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        logger.info(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {token_data.get('symbol', 'UNKNOWN')} -> {prediction_result['prediction']} ({prediction_result['probability_percent']}%)")
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/health', methods=['GET'])
def health():
    """Health check –¥–ª—è Railway"""
    
    model_info = {}
    if model_artifacts:
        model_info = {
            'auc': model_artifacts['performance_metrics']['test_auc'],
            'f1': model_artifacts['performance_metrics']['test_f1'],
            'features_count': len(model_artifacts['feature_names'])
        }
    
    return jsonify({
        'status': 'healthy',
        'model_loaded': model_artifacts is not None,
        'model_info': model_info,
        'timestamp': pd.Timestamp.now().isoformat()
    })

@app.route('/model-info', methods=['GET'])
def model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    # –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    top_features = model_artifacts['feature_importance'].head(10).to_dict('records')
    
    return jsonify({
        'success': True,
        'model_type': model_artifacts.get('model_type', 'Unknown'),
        'training_approach': model_artifacts.get('training_approach', 'Unknown'),
        'performance_metrics': model_artifacts['performance_metrics'],
        'features_count': len(model_artifacts['feature_names']),
        'top_features': top_features,
        'all_features': model_artifacts['feature_names']
    })

@app.route('/example', methods=['GET'])
def example():
    """–ü—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è n8n"""
    
    example_data = {
        "symbol": "BONK",
        "market_cap": 2000000,
        "liquidity": 800000,
        "volume_1m": 100000,
        "buy_volume_1m": 65000,
        "sell_volume_1m": 35000,
        "buyers_green": 150,
        "buyers_blue": 30,
        "buyers_yellow": 20,
        "buyers_red": 15,
        "buyers_clown": 8,
        "buyers_sun": 3,
        "buyers_moon_half": 1,
        "buyers_moon_new": 2,
        "total_holders": 223,
        "top_10_percent": 35.0,
        "dev_current_balance_percent": 5.0,
        "security_no_mint": 1,
        "security_burnt": 1,
        "security_dev_sold": 0,
        "token_age_minutes": 180
    }
    
    return jsonify({
        'example_request': {
            'url': request.base_url.replace('/example', '/predict'),
            'method': 'POST',
            'headers': {
                'Content-Type': 'application/json'
            },
            'body': example_data
        },
        'required_fields': [
            'market_cap', 'liquidity', 'buyers_green', 'buyers_red'
        ],
        'optional_fields': [
            'symbol', 'volume_1m', 'buyers_blue', 'buyers_yellow',
            'buyers_clown', 'buyers_sun', 'buyers_moon_half', 'buyers_moon_new',
            'total_holders', 'top_10_percent', 'dev_current_balance_percent',
            'security_no_mint', 'security_burnt', 'security_dev_sold',
            'token_age_minutes'
        ]
    })

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'success': False,
        'error': 'Endpoint not found',
        'available_endpoints': ['/predict', '/health', '/model-info', '/example']
    }), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'success': False,
        'error': 'Internal server error'
    }), 500

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == '__main__':
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    load_model()
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è (Railway)
    port = int(os.environ.get('PORT', 5000))
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    app.run(host='0.0.0.0', port=port, debug=False), '').strip()
    
    if value_str.endswith('K'):
        return float(value_str[:-1]) * 1000
    elif value_str.endswith('M'):
        return float(value_str[:-1]) * 1000000
    elif value_str.endswith('B'):
        return float(value_str[:-1]) * 1000000000
    else:
        try:
            return float(value_str)
        except:
            return 0

def parse_token_age_minutes(token_age_str):
    """–ü–∞—Ä—Å–∏—Ç –≤–æ–∑—Ä–∞—Å—Ç —Ç–æ–∫–µ–Ω–∞ –≤ –º–∏–Ω—É—Ç—ã"""
    if not token_age_str:
        return 0
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ –∏ –µ–¥–∏–Ω–∏—Ü—É –∏–∑–º–µ—Ä–µ–Ω–∏—è
    match = re.match(r'(\d+)([mhd]?)', str(token_age_str))
    if not match:
        return 0
    
    value = int(match.group(1))
    unit = match.group(2)
    
    if unit == 'm' or unit == '':  # –º–∏–Ω—É—Ç—ã
        return value
    elif unit == 'h':  # —á–∞—Å—ã
        return value * 60
    elif unit == 'd':  # –¥–Ω–∏
        return value * 60 * 24
    else:
        return value

def process_token_data(token_json):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ JSON –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞"""
    
    try:
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        symbol = token_json.get('symbol', 'UNKNOWN')
        token_age_minutes = parse_token_age_minutes(token_json.get('token_age'))
        
        # –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        market_cap = parse_value_with_suffix(token_json.get('market_cap'))
        liquidity = parse_value_with_suffix(token_json.get('liquidity'))
        ath = parse_value_with_suffix(token_json.get('ath'))
        sol_pooled = token_json.get('sol_pooled') or 0
        
        # –û–±—ä–µ–º—ã —Ç–æ—Ä–≥–æ–≤
        volume_1m = token_json.get('volume_1m', 0)
        buy_volume_1m = token_json.get('buy_volume_1m', 0)
        sell_volume_1m = token_json.get('sell_volume_1m', 0)
        buys_1m = token_json.get('buys_1m', 0)
        sells_1m = token_json.get('sells_1m', 0)
        
        volume_5m = token_json.get('volume_5m', 0)
        buy_volume_5m = token_json.get('buy_volume_5m', 0)
        sell_volume_5m = token_json.get('sell_volume_5m', 0)
        buys_5m = token_json.get('buys_5m', 0)
        sells_5m = token_json.get('sells_5m', 0)
        
        # –ü–æ–∫—É–ø–∞—Ç–µ–ª–∏ (–∏–∑ first_buyers)
        first_buyers = token_json.get('first_buyers', {})
        buyers_green = first_buyers.get('green', 0)
        buyers_blue = first_buyers.get('blue', 0)
        buyers_yellow = first_buyers.get('yellow', 0)
        buyers_red = first_buyers.get('red', 0)
        buyers_clown = first_buyers.get('clown', 0)
        buyers_sun = first_buyers.get('sun', 0)
        buyers_moon_half = first_buyers.get('moon_half', 0)
        buyers_moon_new = first_buyers.get('moon_new', 0)
        
        # Current/Initial ratio
        ratio_data = token_json.get('current_initial_ratio', {})
        current_ratio = ratio_data.get('current', 0)
        initial_ratio = ratio_data.get('initial', 0)
        
        # –î–µ—Ä–∂–∞—Ç–µ–ª–∏
        total_holders = token_json.get('total_holders', 0)
        freshies_1d_percent = token_json.get('freshies_1d_percent', 0)
        freshies_7d_percent = token_json.get('freshies_7d_percent', 0)
        top_10_percent = token_json.get('top_10_percent', 0)
        
        # Top 10 holdings - –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        top_10_holdings_list = token_json.get('top_10_holdings', [])
        top_10_holdings = top_10_holdings_list[0] if top_10_holdings_list else 0
        
        # Dev –¥–∞–Ω–Ω—ã–µ
        dev_current_balance_percent = token_json.get('dev_current_balance_percent', 0)
        dev_sol_balance = token_json.get('dev_sol_balance', 0)
        
        # Security –¥–∞–Ω–Ω—ã–µ
        security = token_json.get('security', {})
        security_no_mint = 1 if security.get('no_mint') else 0
        security_blacklist = 1 if security.get('blacklist') else 0
        security_burnt = 1 if security.get('burnt') else 0
        security_dev_sold = 1 if security.get('dev_sold') else 0
        security_dex_paid = 1 if security.get('dex_paid') else 0
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏
        processed_data = {
            'symbol': symbol,
            'token_age_minutes': token_age_minutes,
            'market_cap': market_cap,
            'liquidity': liquidity,
            'sol_pooled': sol_pooled,
            'ath': ath,
            'volume_1m': volume_1m,
            'buy_volume_1m': buy_volume_1m,
            'sell_volume_1m': sell_volume_1m,
            'buys_1m': buys_1m,
            'sells_1m': sells_1m,
            'volume_5m': volume_5m,
            'buy_volume_5m': buy_volume_5m,
            'sell_volume_5m': sell_volume_5m,
            'buys_5m': buys_5m,
            'sells_5m': sells_5m,
            'buyers_green': buyers_green,
            'buyers_blue': buyers_blue,
            'buyers_yellow': buyers_yellow,
            'buyers_red': buyers_red,
            'buyers_clown': buyers_clown,
            'buyers_sun': buyers_sun,
            'buyers_moon_half': buyers_moon_half,
            'buyers_moon_new': buyers_moon_new,
            'current_ratio': current_ratio,
            'initial_ratio': initial_ratio,
            'total_holders': total_holders,
            'freshies_1d_percent': freshies_1d_percent,
            'freshies_7d_percent': freshies_7d_percent,
            'top_10_percent': top_10_percent,
            'top_10_holdings': top_10_holdings,
            'dev_current_balance_percent': dev_current_balance_percent,
            'dev_sol_balance': dev_sol_balance,
            'security_no_mint': security_no_mint,
            'security_blacklist': security_blacklist,
            'security_burnt': security_burnt,
            'security_dev_sold': security_dev_sold,
            'security_dex_paid': security_dex_paid
        }
        
        logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–∞ –¥–ª—è {symbol}: MC=${market_cap:,.0f}, Liq=${liquidity:,.0f}")
        return processed_data
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        raise ValueError(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞: {e}")

def predict_token_success(token_data):
    """–§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–∞"""
    
    if model_artifacts is None:
        raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    try:
        # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        df_new = pd.DataFrame([token_data])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        for col in model_artifacts['feature_names']:
            if col not in df_new.columns:
                df_new[col] = 0
        
        # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
        df_new = df_new[model_artifacts['feature_names']]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–º–ø—É—Ç–µ—Ä
        df_imputed = pd.DataFrame(
            model_artifacts['imputer'].transform(df_new), 
            columns=model_artifacts['feature_names']
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        prediction = model_artifacts['model'].predict(df_imputed)[0]
        probability = model_artifacts['model'].predict_proba(df_imputed)[0, 1]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        confidence_score = abs(probability - 0.5) * 2
        if confidence_score > 0.8:
            confidence_level = "very_high"
        elif confidence_score > 0.6:
            confidence_level = "high"
        elif confidence_score > 0.4:
            confidence_level = "medium"
        else:
            confidence_level = "low"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'prediction': 'success' if prediction == 1 else 'fail',
            'binary_prediction': int(prediction),
            'probability': round(probability, 4),
            'probability_percent': round(probability * 100, 1),
            'confidence_score': round(confidence_score, 4),
            'confidence_level': confidence_level,
            'expected_pnl': 'PNL >= 2x' if prediction == 1 else 'PNL < 2x'
        }
        
        return result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        raise

def analyze_token_signals(token_data):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∏–≥–Ω–∞–ª—ã —Ç–æ–∫–µ–Ω–∞"""
    
    # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã (—Ö–æ–ª–¥—è—Ç –∏ –¥–æ–∫—É–ø–∞—é—Ç)
    positive = (token_data.get('buyers_green', 0) + 
                token_data.get('buyers_blue', 0) + 
                token_data.get('buyers_clown', 0) + 
                token_data.get('buyers_sun', 0))
    
    # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã (–ø—Ä–æ–¥–∞–ª–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é)
    negative = (token_data.get('buyers_red', 0) + 
                token_data.get('buyers_moon_new', 0))
    
    # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ
    ratio = positive / (negative + 1)
    
    if ratio > 3:
        status = "very_good"
    elif ratio > 1.5:
        status = "good"
    elif ratio > 0.8:
        status = "medium"
    else:
        status = "bad"
    
    return {
        'positive_signals': positive,
        'negative_signals': negative,
        'signal_ratio': round(ratio, 2),
        'signal_status': status
    }

def check_token_safety(token_data):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞"""
    
    safety_score = 0
    issues = []
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—é
    top10 = token_data.get('top_10_percent', 0)
    if top10 <= 70:
        safety_score += 1
    else:
        issues.append(f"high_concentration_{top10}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
    dev_percent = token_data.get('dev_current_balance_percent', 0)
    if dev_percent <= 20:
        safety_score += 1
    else:
        issues.append(f"dev_holds_much_{dev_percent}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
    liquidity = token_data.get('liquidity', 0)
    if liquidity >= 100000:
        safety_score += 1
    else:
        issues.append(f"low_liquidity_{liquidity}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
    if token_data.get('security_no_mint', 0):
        safety_score += 1
    else:
        issues.append("mint_not_disabled")
        
    if token_data.get('security_burnt', 0):
        safety_score += 1
    else:
        issues.append("tokens_not_burnt")
    
    return {
        'safety_score': safety_score,
        'max_safety_score': 5,
        'safety_percentage': round((safety_score / 5) * 100),
        'safety_issues': issues,
        'is_safe': safety_score >= 3
    }

def get_recommendation(prediction_result, signals, safety):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é"""
    
    probability = prediction_result['probability']
    safety_score = safety['safety_score']
    
    if probability >= 0.7 and safety_score >= 4:
        return {
            'recommendation': 'BUY',
            'risk_level': 'low',
            'reason': 'excellent_token'
        }
    elif probability >= 0.6 and safety_score >= 3:
        return {
            'recommendation': 'CONSIDER',
            'risk_level': 'medium',
            'reason': 'good_potential'
        }
    elif probability >= 0.5 and safety_score >= 2:
        return {
            'recommendation': 'CAUTION',
            'risk_level': 'medium_high',
            'reason': 'moderate_risk'
        }
    else:
        return {
            'recommendation': 'AVOID',
            'risk_level': 'high',
            'reason': 'high_risk'
        }

# =============================================================================
# API ENDPOINTS
# =============================================================================

@app.route('/', methods=['GET'])
def home():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ API"""
    return jsonify({
        'service': 'Solana Token Predictor API',
        'status': 'online',
        'model_loaded': model_artifacts is not None,
        'endpoints': {
            'predict': '/predict [POST]',
            'predict_batch': '/predict-batch [POST]',
            'health': '/health [GET]',
            'model_info': '/model-info [GET]'
        }
    })

@app.route('/predict', methods=['POST'])
def predict():
    """–û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Content-Type must be application/json'
            }), 400
        
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏—à–ª–∏ –≤ –≤–∏–¥–µ –º–∞—Å—Å–∏–≤–∞, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç
        if isinstance(data, list):
            if len(data) == 0:
                return jsonify({
                    'success': False,
                    'error': 'Empty array provided'
                }), 400
            token_json = data[0]
        else:
            token_json = data
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞
        processed_token_data = process_token_data(token_json)
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prediction_result = predict_token_success(processed_token_data)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
        signals = analyze_token_signals(processed_token_data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        safety = check_token_safety(processed_token_data)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
        recommendation = get_recommendation(prediction_result, signals, safety)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = {
            'success': True,
            'token_symbol': processed_token_data.get('symbol', 'UNKNOWN'),
            'processed_data': processed_token_data,
            'prediction': prediction_result,
            'signals': signals,
            'safety': safety,
            'recommendation': recommendation,
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        logger.info(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {processed_token_data.get('symbol', 'UNKNOWN')} -> {prediction_result['prediction']} ({prediction_result['probability_percent']}%)")
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/predict-batch', methods=['POST'])
def predict_batch():
    """Endpoint –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Content-Type must be application/json'
            }), 400
        
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–∞—Å—Å–∏–≤ —Ç–æ–∫–µ–Ω–æ–≤
        if not isinstance(data, list):
            return jsonify({
                'success': False,
                'error': 'Expected array of tokens'
            }), 400
        
        results = []
        
        for i, token_json in enumerate(data):
            try:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω
                processed_token_data = process_token_data(token_json)
                prediction_result = predict_token_success(processed_token_data)
                signals = analyze_token_signals(processed_token_data)
                safety = check_token_safety(processed_token_data)
                recommendation = get_recommendation(prediction_result, signals, safety)
                
                token_result = {
                    'index': i,
                    'success': True,
                    'token_symbol': processed_token_data.get('symbol', 'UNKNOWN'),
                    'prediction': prediction_result,
                    'signals': signals,
                    'safety': safety,
                    'recommendation': recommendation
                }
                
                results.append(token_result)
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–∫–µ–Ω–∞ {i}: {e}")
                results.append({
                    'index': i,
                    'success': False,
                    'error': str(e),
                    'token_symbol': token_json.get('symbol', 'UNKNOWN')
                })
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        successful = sum(1 for r in results if r.get('success'))
        failed = len(results) - successful
        
        response = {
            'success': True,
            'total_tokens': len(data),
            'successful_predictions': successful,
            'failed_predictions': failed,
            'results': results,
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        logger.info(f"‚úÖ –ü–∞–∫–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {successful}/{len(data)} —É—Å–ø–µ—à–Ω–æ")
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ API: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/health', methods=['GET'])
def health():
    """Health check –¥–ª—è Railway"""
    
    model_info = {}
    if model_artifacts:
        model_info = {
            'auc': model_artifacts['performance_metrics']['test_auc'],
            'f1': model_artifacts['performance_metrics']['test_f1'],
            'features_count': len(model_artifacts['feature_names'])
        }
    
    return jsonify({
        'status': 'healthy',
        'model_loaded': model_artifacts is not None,
        'model_info': model_info,
        'timestamp': pd.Timestamp.now().isoformat()
    })

@app.route('/model-info', methods=['GET'])
def model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    # –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    top_features = model_artifacts['feature_importance'].head(10).to_dict('records')
    
    return jsonify({
        'success': True,
        'model_type': model_artifacts.get('model_type', 'Unknown'),
        'training_approach': model_artifacts.get('training_approach', 'Unknown'),
        'performance_metrics': model_artifacts['performance_metrics'],
        'features_count': len(model_artifacts['feature_names']),
        'top_features': top_features,
        'all_features': model_artifacts['feature_names']
    })

@app.route('/example', methods=['GET'])
def example():
    """–ü—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º JSON —Ñ–æ—Ä–º–∞—Ç–µ"""
    
    example_data = {
        "symbol": "CRUMB",
        "name": "Crumbcat",
        "contract_address": "Hz7MeU72BNF9rCWyUFAwKTyCcjr6qsJm1jwYehnqjups",
        "token_age": "2m",
        "views": 59,
        "market_cap": "129.1K",
        "liquidity": "47.3K",
        "sol_pooled": None,
        "ath": "152.7K",
        "ath_change_percent": -21,
        "ath_time_ago": "32s",
        "volume_1m": 148947.33,
        "buy_volume_1m": 81396.06,
        "sell_volume_1m": 67551.28,
        "buys_1m": 567,
        "sells_1m": 453,
        "volume_5m": 172794.94,
        "buy_volume_5m": 98494.49,
        "sell_volume_5m": 74300.45,
        "buys_5m": 670,
        "sells_5m": 517,
        "first_buyers": {
            "visual_map": "‚≠ï‚≠ï‚≠ï‚≠ïüü°‚≠ïüîµ‚≠ï‚≠ïüü°üü°üü°‚≠ïüü°‚≠ïüü°‚≠ï‚≠ï‚≠ï‚≠ï‚≠ïüü°üü°‚≠ïüü¢üü°üü°‚≠ï‚≠ï‚≠ïüü°üü°üü¢üü¢‚≠ïüü°üü°üü¢üü°üü°üü°‚≠ïüü°üü°üü¢üü¢üü¢‚≠ï‚≠ïüü°üü¢üü°‚≠ïüü°üü°üü¢üü°üîµüü°‚≠ï‚≠ïüü¢üü°üü¢‚≠ï‚≠ïüü¢üü¢üü¢üü°",
            "green": 14,
            "blue": 2,
            "yellow": 27,
            "red": 27,
            "clown": 0,
            "sun": 0,
            "moon_half": 0,
            "moon_new": 0
        },
        "current_initial_ratio": {
            "current": 23.8,
            "initial": 72.58
        },
        "total_holders": 383,
        "freshies_1d_percent": 5.5,
        "freshies_7d_percent": 18,
        "top_10_percent": 21,
        "top_10_holdings": [29.2, 3.38, 3.32, 2.96, 2.95, 2.56, 2.49, 2.26, 1.95, 1.89],
        "dev_current_balance_percent": 0,
        "dev_sol_balance": 0.225,
        "security": {
            "no_mint": True,
            "blacklist": True,
            "burnt": True,
            "dev_sold": True,
            "dex_paid": False
        }
    }
    
    return jsonify({
        'single_token_request': {
            'url': request.base_url.replace('/example', '/predict'),
            'method': 'POST',
            'headers': {
                'Content-Type': 'application/json'
            },
            'body': example_data
        },
        'array_request': {
            'url': request.base_url.replace('/example', '/predict'),
            'method': 'POST',
            'headers': {
                'Content-Type': 'application/json'
            },
            'body': [example_data]
        },
        'batch_request': {
            'url': request.base_url.replace('/example', '/predict-batch'),
            'method': 'POST',
            'headers': {
                'Content-Type': 'application/json'
            },
            'body': [example_data, example_data]
        }
    })

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'success': False,
        'error': 'Endpoint not found',
        'available_endpoints': ['/predict', '/predict-batch', '/health', '/model-info', '/example']
    }), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'success': False,
        'error': 'Internal server error'
    }), 500

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == '__main__':
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    load_model()
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è (Railway)
    port = int(os.environ.get('PORT', 5000))
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    app.run(host='0.0.0.0', port=port, debug=False)
import os
import pickle
import pandas as pd
import numpy as np
import re
from flask import Flask, request, jsonify
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –º–æ–¥–µ–ª–∏
model_artifacts = None

def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    global model_artifacts
    try:
        model_file = 'solana_token_xgboost_model.pkl'
        if os.path.exists(model_file):
            with open(model_file, 'rb') as f:
                model_artifacts = pickle.load(f)
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞! AUC: {model_artifacts['performance_metrics']['test_auc']:.4f}")
            return True
        else:
            logger.error(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ {model_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return False

def parse_token_data(cena_full_text):
    """–ü–∞—Ä—Å–∏—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç"""
    
    try:
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Å–∏–º–≤–æ–ª —Ç–æ–∫–µ–Ω–∞
        symbol_match = re.search(r'\$([A-Z0-9]+)', cena_full_text)
        symbol = symbol_match.group(1) if symbol_match else "UNKNOWN"
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º –≤–æ–∑—Ä–∞—Å—Ç —Ç–æ–∫–µ–Ω–∞ (–≤ –º–∏–Ω—É—Ç–∞—Ö)
        age_match = re.search(r'Token age:\s*(\d+)m', cena_full_text)
        token_age_minutes = int(age_match.group(1)) if age_match else 0
        
        # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ä—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        mc_match = re.search(r'MC: \$([0-9,\.]+)K', cena_full_text)
        market_cap = float(mc_match.group(1).replace(',', '')) * 1000 if mc_match else 0
        
        liq_match = re.search(r'Liq: \$([0-9,\.]+)K', cena_full_text)
        liquidity = float(liq_match.group(1).replace(',', '')) * 1000 if liq_match else 0
        
        # SOL pooled
        sol_match = re.search(r'SOL pooled: ([0-9,\.]+)', cena_full_text)
        sol_pooled = float(sol_match.group(1).replace(',', '')) if sol_match else 0
        
        # ATH
        ath_match = re.search(r'ATH: \$([0-9,\.]+)K', cena_full_text)
        ath = float(ath_match.group(1).replace(',', '')) * 1000 if ath_match else 0
        
        # –û–±—ä–µ–º—ã 1 –º–∏–Ω—É—Ç–∞
        vol_1m_match = re.search(r'Volume: \$([0-9,\.]+)', cena_full_text)
        volume_1m = float(vol_1m_match.group(1).replace(',', '')) if vol_1m_match else 0
        
        buy_vol_1m_match = re.search(r'Buy volume \(\$\): \$([0-9,\.]+)', cena_full_text)
        buy_volume_1m = float(buy_vol_1m_match.group(1).replace(',', '')) if buy_vol_1m_match else 0
        
        sell_vol_1m_match = re.search(r'Sell volume \(\$\): \$([0-9,\.]+)', cena_full_text)
        sell_volume_1m = float(sell_vol_1m_match.group(1).replace(',', '')) if sell_vol_1m_match else 0
        
        # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–∫—É–ø–æ–∫/–ø—Ä–æ–¥–∞–∂
        buys_1m_match = re.search(r'Buys: (\d+)', cena_full_text)
        buys_1m = int(buys_1m_match.group(1)) if buys_1m_match else 0
        
        sells_1m_match = re.search(r'Sells: (\d+)', cena_full_text)
        sells_1m = int(sells_1m_match.group(1)) if sells_1m_match else 0
        
        # –û–±—ä–µ–º—ã 5 –º–∏–Ω—É—Ç (–∏—â–µ–º –≤—Ç–æ—Ä—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è)
        vol_5m_matches = re.findall(r'Volume: \$([0-9,\.]+)', cena_full_text)
        volume_5m = float(vol_5m_matches[1].replace(',', '')) if len(vol_5m_matches) > 1 else 0
        
        buy_vol_5m_matches = re.findall(r'Buy volume \(\$\): \$([0-9,\.]+)', cena_full_text)
        buy_volume_5m = float(buy_vol_5m_matches[1].replace(',', '')) if len(buy_vol_5m_matches) > 1 else 0
        
        sell_vol_5m_matches = re.findall(r'Sell volume \(\$\): \$([0-9,\.]+)', cena_full_text)
        sell_volume_5m = float(sell_vol_5m_matches[1].replace(',', '')) if len(sell_vol_5m_matches) > 1 else 0
        
        buys_5m_matches = re.findall(r'Buys: (\d+)', cena_full_text)
        buys_5m = int(buys_5m_matches[1]) if len(buys_5m_matches) > 1 else 0
        
        sells_5m_matches = re.findall(r'Sells: (\d+)', cena_full_text)
        sells_5m = int(sells_5m_matches[1]) if len(sells_5m_matches) > 1 else 0
        
        # –ü–æ–∫—É–ø–∞—Ç–µ–ª–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        green_match = re.search(r'üü¢: (\d+)', cena_full_text)
        buyers_green = int(green_match.group(1)) if green_match else 0
        
        blue_match = re.search(r'üîµ: (\d+)', cena_full_text)
        buyers_blue = int(blue_match.group(1)) if blue_match else 0
        
        yellow_match = re.search(r'üü°: (\d+)', cena_full_text)
        buyers_yellow = int(yellow_match.group(1)) if yellow_match else 0
        
        red_match = re.search(r'‚≠ïÔ∏è: (\d+)', cena_full_text)
        buyers_red = int(red_match.group(1)) if red_match else 0
        
        # –°–Ω–∞–π–ø–µ—Ä—ã
        clown_match = re.search(r'ü§°: (\d+)', cena_full_text)
        buyers_clown = int(clown_match.group(1)) if clown_match else 0
        
        sun_match = re.search(r'üåû: (\d+)', cena_full_text)
        buyers_sun = int(sun_match.group(1)) if sun_match else 0
        
        moon_half_match = re.search(r'üåó: (\d+)', cena_full_text)
        buyers_moon_half = int(moon_half_match.group(1)) if moon_half_match else 0
        
        moon_new_match = re.search(r'üåö: (\d+)', cena_full_text)
        buyers_moon_new = int(moon_new_match.group(1)) if moon_new_match else 0
        
        # Current/Initial ratio
        ratio_match = re.search(r'Current/Initial: ([0-9\.]+)% / ([0-9\.]+)%', cena_full_text)
        current_ratio = float(ratio_match.group(1)) if ratio_match else 0
        initial_ratio = float(ratio_match.group(2)) if ratio_match else 0
        
        # –î–µ—Ä–∂–∞—Ç–µ–ª–∏
        total_holders_match = re.search(r'Total: (\d+)', cena_full_text)
        total_holders = int(total_holders_match.group(1)) if total_holders_match else 0
        
        freshies_1d_match = re.search(r'Freshies: ([0-9\.]+)% 1D', cena_full_text)
        freshies_1d_percent = float(freshies_1d_match.group(1)) if freshies_1d_match else 0
        
        freshies_7d_match = re.search(r'([0-9\.]+)% 7D', cena_full_text)
        freshies_7d_percent = float(freshies_7d_match.group(1)) if freshies_7d_match else 0
        
        top_10_match = re.search(r'Top 10: (\d+)%', cena_full_text)
        top_10_percent = float(top_10_match.group(1)) if top_10_match else 0
        
        # Top 10 holdings - –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        holdings_match = re.search(r'Top 10 Holding.*?\n([0-9\.]+)', cena_full_text, re.DOTALL)
        top_10_holdings = float(holdings_match.group(1)) if holdings_match else 0
        
        # Dev –¥–∞–Ω–Ω—ã–µ
        dev_balance_match = re.search(r'Dev current balance: (\d+)%', cena_full_text)
        dev_current_balance_percent = float(dev_balance_match.group(1)) if dev_balance_match else 0
        
        dev_sol_match = re.search(r'Dev SOL balance: ([0-9\.]+) SOL', cena_full_text)
        dev_sol_balance = float(dev_sol_match.group(1)) if dev_sol_match else 0
        
        # Security flags (üü¢ = 1, üî¥ = 0)
        security_no_mint = 1 if '‚îú NoMint: üü¢' in cena_full_text else 0
        security_blacklist = 1 if '‚îú Blacklist: üü¢' in cena_full_text else 0
        security_burnt = 1 if '‚îú Burnt: üü¢' in cena_full_text else 0
        security_dev_sold = 1 if '‚îú Dev Sold: üü¢' in cena_full_text else 0
        security_dex_paid = 1 if '‚îî Dex Paid: üü¢' in cena_full_text else 0
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        parsed_data = {
            'symbol': symbol,
            'token_age_minutes': token_age_minutes,
            'market_cap': market_cap,
            'liquidity': liquidity,
            'sol_pooled': sol_pooled,
            'ath': ath,
            'volume_1m': volume_1m,
            'buy_volume_1m': buy_volume_1m,
            'sell_volume_1m': sell_volume_1m,
            'buys_1m': buys_1m,
            'sells_1m': sells_1m,
            'volume_5m': volume_5m,
            'buy_volume_5m': buy_volume_5m,
            'sell_volume_5m': sell_volume_5m,
            'buys_5m': buys_5m,
            'sells_5m': sells_5m,
            'buyers_green': buyers_green,
            'buyers_blue': buyers_blue,
            'buyers_yellow': buyers_yellow,
            'buyers_red': buyers_red,
            'buyers_clown': buyers_clown,
            'buyers_sun': buyers_sun,
            'buyers_moon_half': buyers_moon_half,
            'buyers_moon_new': buyers_moon_new,
            'current_ratio': current_ratio,
            'initial_ratio': initial_ratio,
            'total_holders': total_holders,
            'freshies_1d_percent': freshies_1d_percent,
            'freshies_7d_percent': freshies_7d_percent,
            'top_10_percent': top_10_percent,
            'top_10_holdings': top_10_holdings,
            'dev_current_balance_percent': dev_current_balance_percent,
            'dev_sol_balance': dev_sol_balance,
            'security_no_mint': security_no_mint,
            'security_blacklist': security_blacklist,
            'security_burnt': security_burnt,
            'security_dev_sold': security_dev_sold,
            'security_dex_paid': security_dex_paid
        }
        
        logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ —É—Å–ø–µ—à–µ–Ω –¥–ª—è {symbol}: MC=${market_cap:,.0f}, Liq=${liquidity:,.0f}")
        return parsed_data
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
        raise ValueError(f"–û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞: {e}")

def predict_token_success(token_data):
    """–§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–∞"""
    
    if model_artifacts is None:
        raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    try:
        # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        df_new = pd.DataFrame([token_data])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        for col in model_artifacts['feature_names']:
            if col not in df_new.columns:
                df_new[col] = 0
        
        # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
        df_new = df_new[model_artifacts['feature_names']]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–º–ø—É—Ç–µ—Ä
        df_imputed = pd.DataFrame(
            model_artifacts['imputer'].transform(df_new), 
            columns=model_artifacts['feature_names']
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è (Railway)
    port = int(os.environ.get('PORT', 5000))
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    app.run(host='0.0.0.0', port=port, debug=False)–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        prediction = model_artifacts['model'].predict(df_imputed)[0]
        probability = model_artifacts['model'].predict_proba(df_imputed)[0, 1]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        confidence_score = abs(probability - 0.5) * 2
        if confidence_score > 0.8:
            confidence_level = "very_high"
        elif confidence_score > 0.6:
            confidence_level = "high"
        elif confidence_score > 0.4:
            confidence_level = "medium"
        else:
            confidence_level = "low"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'prediction': 'success' if prediction == 1 else 'fail',
            'binary_prediction': int(prediction),
            'probability': round(probability, 4),
            'probability_percent': round(probability * 100, 1),
            'confidence_score': round(confidence_score, 4),
            'confidence_level': confidence_level,
            'expected_pnl': 'PNL >= 2x' if prediction == 1 else 'PNL < 2x'
        }
        
        return result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        raise

def analyze_token_signals(token_data):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∏–≥–Ω–∞–ª—ã —Ç–æ–∫–µ–Ω–∞"""
    
    # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã (—Ö–æ–ª–¥—è—Ç –∏ –¥–æ–∫—É–ø–∞—é—Ç)
    positive = (token_data.get('buyers_green', 0) + 
                token_data.get('buyers_blue', 0) + 
                token_data.get('buyers_clown', 0) + 
                token_data.get('buyers_sun', 0))
    
    # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã (–ø—Ä–æ–¥–∞–ª–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é)
    negative = (token_data.get('buyers_red', 0) + 
                token_data.get('buyers_moon_new', 0))
    
    # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ
    ratio = positive / (negative + 1)
    
    if ratio > 3:
        status = "very_good"
    elif ratio > 1.5:
        status = "good"
    elif ratio > 0.8:
        status = "medium"
    else:
        status = "bad"
    
    return {
        'positive_signals': positive,
        'negative_signals': negative,
        'signal_ratio': round(ratio, 2),
        'signal_status': status
    }

def check_token_safety(token_data):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞"""
    
    safety_score = 0
    issues = []
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—é
    top10 = token_data.get('top_10_percent', 0)
    if top10 <= 70:
        safety_score += 1
    else:
        issues.append(f"high_concentration_{top10}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
    dev_percent = token_data.get('dev_current_balance_percent', 0)
    if dev_percent <= 20:
        safety_score += 1
    else:
        issues.append(f"dev_holds_much_{dev_percent}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
    liquidity = token_data.get('liquidity', 0)
    if liquidity >= 100000:
        safety_score += 1
    else:
        issues.append(f"low_liquidity_{liquidity}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
    if token_data.get('security_no_mint', 0):
        safety_score += 1
    else:
        issues.append("mint_not_disabled")
        
    if token_data.get('security_burnt', 0):
        safety_score += 1
    else:
        issues.append("tokens_not_burnt")
    
    return {
        'safety_score': safety_score,
        'max_safety_score': 5,
        'safety_percentage': round((safety_score / 5) * 100),
        'safety_issues': issues,
        'is_safe': safety_score >= 3
    }

def get_recommendation(prediction_result, signals, safety):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é"""
    
    probability = prediction_result['probability']
    safety_score = safety['safety_score']
    
    if probability >= 0.7 and safety_score >= 4:
        return {
            'recommendation': 'BUY',
            'risk_level': 'low',
            'reason': 'excellent_token'
        }
    elif probability >= 0.6 and safety_score >= 3:
        return {
            'recommendation': 'CONSIDER',
            'risk_level': 'medium',
            'reason': 'good_potential'
        }
    elif probability >= 0.5 and safety_score >= 2:
        return {
            'recommendation': 'CAUTION',
            'risk_level': 'medium_high',
            'reason': 'moderate_risk'
        }
    else:
        return {
            'recommendation': 'AVOID',
            'risk_level': 'high',
            'reason': 'high_risk'
        }

# =============================================================================
# API ENDPOINTS
# =============================================================================

@app.route('/', methods=['GET'])
def home():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ API"""
    return jsonify({
        'service': 'Solana Token Predictor API',
        'status': 'online',
        'model_loaded': model_artifacts is not None,
        'endpoints': {
            'predict': '/predict [POST]',
            'predict_text': '/predict-text [POST]',
            'health': '/health [GET]',
            'model_info': '/model-info [GET]'
        }
    })

@app.route('/predict-text', methods=['POST'])
def predict_text():
    """Endpoint –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–æ—Å–Ω–æ–≤–Ω–æ–π –¥–ª—è n8n)"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Content-Type must be application/json'
            }), 400
        
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        # –û–∂–∏–¥–∞–µ–º –ø–æ–ª–µ cena_full —Å —Ç–µ–∫—Å—Ç–æ–≤—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        cena_full_text = data.get('cena_full')
        if not cena_full_text:
            return jsonify({
                'success': False,
                'error': 'Field "cena_full" is required'
            }), 400
        
        # –ü–∞—Ä—Å–∏–º —Ç–µ–∫—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        parsed_token_data = parse_token_data(cena_full_text)
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prediction_result = predict_token_success(parsed_token_data)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
        signals = analyze_token_signals(parsed_token_data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        safety = check_token_safety(parsed_token_data)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
        recommendation = get_recommendation(prediction_result, signals, safety)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = {
            'success': True,
            'token_symbol': parsed_token_data.get('symbol', 'UNKNOWN'),
            'parsed_data': parsed_token_data,
            'prediction': prediction_result,
            'signals': signals,
            'safety': safety,
            'recommendation': recommendation,
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        logger.info(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {parsed_token_data.get('symbol', 'UNKNOWN')} -> {prediction_result['prediction']} ({prediction_result['probability_percent']}%)")
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/predict', methods=['POST'])
def predict():
    """Endpoint –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Content-Type must be application/json'
            }), 400
        
        token_data = request.get_json()
        
        if not token_data:
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prediction_result = predict_token_success(token_data)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
        signals = analyze_token_signals(token_data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        safety = check_token_safety(token_data)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
        recommendation = get_recommendation(prediction_result, signals, safety)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = {
            'success': True,
            'token_symbol': token_data.get('symbol', 'UNKNOWN'),
            'prediction': prediction_result,
            'signals': signals,
            'safety': safety,
            'recommendation': recommendation,
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        logger.info(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {token_data.get('symbol', 'UNKNOWN')} -> {prediction_result['prediction']} ({prediction_result['probability_percent']}%)")
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/health', methods=['GET'])
def health():
    """Health check –¥–ª—è Railway"""
    
    model_info = {}
    if model_artifacts:
        model_info = {
            'auc': model_artifacts['performance_metrics']['test_auc'],
            'f1': model_artifacts['performance_metrics']['test_f1'],
            'features_count': len(model_artifacts['feature_names'])
        }
    
    return jsonify({
        'status': 'healthy',
        'model_loaded': model_artifacts is not None,
        'model_info': model_info,
        'timestamp': pd.Timestamp.now().isoformat()
    })

@app.route('/model-info', methods=['GET'])
def model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    # –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    top_features = model_artifacts['feature_importance'].head(10).to_dict('records')
    
    return jsonify({
        'success': True,
        'model_type': model_artifacts.get('model_type', 'Unknown'),
        'training_approach': model_artifacts.get('training_approach', 'Unknown'),
        'performance_metrics': model_artifacts['performance_metrics'],
        'features_count': len(model_artifacts['feature_names']),
        'top_features': top_features,
        'all_features': model_artifacts['feature_names']
    })

@app.route('/example-text', methods=['GET'])
def example_text():
    """–ü—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Ç–µ–∫—Å—Ç–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ"""
    
    example_data = {
        "cena_full": "üé≤ $CRUMB | Crumbcat\nHz7MeU72BNF9rCWyUFAwKTyCcjr6qsJm1jwYehnqjups\n‚è≥ Token age:  2m  | üëÅ 59\n‚îú MC: $129.1K\n‚îú Liq: $47.3K / SOL pooled: --\n‚îî ATH: $152.7K (-21% / 32s)\n1 min:\n‚îú Volume: $148,947.33\n‚îú Buy volume ($): $81,396.06\n‚îú Sell volume ($): $67,551.28\n‚îú Buys: 567\n‚îî Sells: 453\n5 min:\n‚îú Volume: $172,794.94\n‚îú Buy volume ($): $98,494.49\n‚îú Sell volume ($): $74,300.45\n‚îú Buys: 670\n‚îî Sells: 517\nüéØ First 70 buyers:\n‚≠ïÔ∏è‚≠ïÔ∏è‚≠ïÔ∏è‚≠ïÔ∏èüü°‚≠ïÔ∏èüîµ‚≠ïÔ∏è‚≠ïÔ∏èüü°\nüü°üü°‚≠ïÔ∏èüü°‚≠ïÔ∏èüü°‚≠ïÔ∏è‚≠ïÔ∏è‚≠ïÔ∏è‚≠ïÔ∏è\n‚≠ïÔ∏èüü°üü°‚≠ïÔ∏èüü¢üü°üü°‚≠ïÔ∏è‚≠ïÔ∏è‚≠ïÔ∏è\nüü°üü°üü¢üü¢‚≠ïÔ∏èüü°üü°üü¢üü°üü°\nüü°‚≠ïÔ∏èüü°üü°üü¢üü¢üü¢‚≠ïÔ∏è‚≠ïÔ∏èüü°\nüü¢üü°‚≠ïÔ∏èüü°üü°üü¢üü°üîµüü°‚≠ïÔ∏è\n‚≠ïÔ∏èüü¢üü°üü¢‚≠ïÔ∏è‚≠ïÔ∏èüü¢üü¢üü¢üü°\n‚îú üü¢: 14 | üîµ: 2 | üü°: 27 | ‚≠ïÔ∏è: 27\n‚îú ü§°: 0 | üåû: 0 | üåó: 0 | üåö: 0\n‚îú Current/Initial: 23.8% / 72.58%\nüë• Holders:\n‚îú Total: 383\n‚îú Freshies: 5.5% 1D | 18% 7D\n‚îú Top 10: 21%\nüí∞ Top 10 Holding (%)\n29.2 | 3.38 | 3.32 | 2.96 | 2.95 | 2.56 | 2.49 | 2.26 | 1.95 | 1.89\nüòé Dev\n‚îú Dev current balance: 0%\n‚îî Dev SOL balance: 0.225 SOL\nüîí Security:\n‚îú NoMint: üü¢\n‚îú Blacklist: üü¢\n‚îú Burnt: üü¢\n‚îú Dev Sold: üü¢\n‚îî Dex Paid: üî¥"
    }
    
    return jsonify({
        'example_request': {
            'url': request.base_url.replace('/example-text', '/predict-text'),
            'method': 'POST',
            'headers': {
                'Content-Type': 'application/json'
            },
            'body': example_data
        },
        'required_fields': [
            'cena_full (string with full token data)'
        ],
        'note': 'Send the complete text data in cena_full field'
    })

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'success': False,
        'error': 'Endpoint not found',
        'available_endpoints': ['/predict-text', '/predict', '/health', '/model-info', '/example-text']
    }), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'success': False,
        'error': 'Internal server error'
    }), 500

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == '__main__':
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    load_model()
    
    # –ü–æ–ª—É—á# app.py - –ü—Ä–æ—Å—Ç–æ–π API –¥–ª—è Railway + n8n
import os
import pickle
import pandas as pd
import numpy as np
from flask import Flask, request, jsonify
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –º–æ–¥–µ–ª–∏
model_artifacts = None

def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    global model_artifacts
    try:
        model_file = 'solana_token_xgboost_model.pkl'
        if os.path.exists(model_file):
            with open(model_file, 'rb') as f:
                model_artifacts = pickle.load(f)
            logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞! AUC: {model_artifacts['performance_metrics']['test_auc']:.4f}")
            return True
        else:
            logger.error(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ {model_file} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            return False
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return False

def predict_token_success(token_data):
    """–§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–∞"""
    
    if model_artifacts is None:
        raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    try:
        # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        df_new = pd.DataFrame([token_data])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        for col in model_artifacts['feature_names']:
            if col not in df_new.columns:
                df_new[col] = 0
        
        # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
        df_new = df_new[model_artifacts['feature_names']]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–º–ø—É—Ç–µ—Ä
        df_imputed = pd.DataFrame(
            model_artifacts['imputer'].transform(df_new), 
            columns=model_artifacts['feature_names']
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        prediction = model_artifacts['model'].predict(df_imputed)[0]
        probability = model_artifacts['model'].predict_proba(df_imputed)[0, 1]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        confidence_score = abs(probability - 0.5) * 2
        if confidence_score > 0.8:
            confidence_level = "very_high"
        elif confidence_score > 0.6:
            confidence_level = "high"
        elif confidence_score > 0.4:
            confidence_level = "medium"
        else:
            confidence_level = "low"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'prediction': 'success' if prediction == 1 else 'fail',
            'binary_prediction': int(prediction),
            'probability': round(probability, 4),
            'probability_percent': round(probability * 100, 1),
            'confidence_score': round(confidence_score, 4),
            'confidence_level': confidence_level,
            'expected_pnl': 'PNL >= 2x' if prediction == 1 else 'PNL < 2x'
        }
        
        return result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        raise

def analyze_token_signals(token_data):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∏–≥–Ω–∞–ª—ã —Ç–æ–∫–µ–Ω–∞"""
    
    # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã (—Ö–æ–ª–¥—è—Ç –∏ –¥–æ–∫—É–ø–∞—é—Ç)
    positive = (token_data.get('buyers_green', 0) + 
                token_data.get('buyers_blue', 0) + 
                token_data.get('buyers_clown', 0) + 
                token_data.get('buyers_sun', 0))
    
    # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã (–ø—Ä–æ–¥–∞–ª–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é)
    negative = (token_data.get('buyers_red', 0) + 
                token_data.get('buyers_moon_new', 0))
    
    # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ
    ratio = positive / (negative + 1)
    
    if ratio > 3:
        status = "very_good"
    elif ratio > 1.5:
        status = "good"
    elif ratio > 0.8:
        status = "medium"
    else:
        status = "bad"
    
    return {
        'positive_signals': positive,
        'negative_signals': negative,
        'signal_ratio': round(ratio, 2),
        'signal_status': status
    }

def check_token_safety(token_data):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞"""
    
    safety_score = 0
    issues = []
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—é
    top10 = token_data.get('top_10_percent', 0)
    if top10 <= 70:
        safety_score += 1
    else:
        issues.append(f"high_concentration_{top10}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
    dev_percent = token_data.get('dev_current_balance_percent', 0)
    if dev_percent <= 20:
        safety_score += 1
    else:
        issues.append(f"dev_holds_much_{dev_percent}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
    liquidity = token_data.get('liquidity', 0)
    if liquidity >= 100000:
        safety_score += 1
    else:
        issues.append(f"low_liquidity_{liquidity}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
    if token_data.get('security_no_mint', 0):
        safety_score += 1
    else:
        issues.append("mint_not_disabled")
        
    if token_data.get('security_burnt', 0):
        safety_score += 1
    else:
        issues.append("tokens_not_burnt")
    
    return {
        'safety_score': safety_score,
        'max_safety_score': 5,
        'safety_percentage': round((safety_score / 5) * 100),
        'safety_issues': issues,
        'is_safe': safety_score >= 3
    }

def get_recommendation(prediction_result, signals, safety):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é"""
    
    probability = prediction_result['probability']
    safety_score = safety['safety_score']
    
    if probability >= 0.7 and safety_score >= 4:
        return {
            'recommendation': 'BUY',
            'risk_level': 'low',
            'reason': 'excellent_token'
        }
    elif probability >= 0.6 and safety_score >= 3:
        return {
            'recommendation': 'CONSIDER',
            'risk_level': 'medium',
            'reason': 'good_potential'
        }
    elif probability >= 0.5 and safety_score >= 2:
        return {
            'recommendation': 'CAUTION',
            'risk_level': 'medium_high',
            'reason': 'moderate_risk'
        }
    else:
        return {
            'recommendation': 'AVOID',
            'risk_level': 'high',
            'reason': 'high_risk'
        }

# =============================================================================
# API ENDPOINTS
# =============================================================================

@app.route('/', methods=['GET'])
def home():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ API"""
    return jsonify({
        'service': 'Solana Token Predictor API',
        'status': 'online',
        'model_loaded': model_artifacts is not None,
        'endpoints': {
            'predict': '/predict [POST]',
            'health': '/health [GET]',
            'model_info': '/model-info [GET]'
        }
    })

@app.route('/predict', methods=['POST'])
def predict():
    """–û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Content-Type must be application/json'
            }), 400
        
        token_data = request.get_json()
        
        if not token_data:
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prediction_result = predict_token_success(token_data)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
        signals = analyze_token_signals(token_data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        safety = check_token_safety(token_data)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
        recommendation = get_recommendation(prediction_result, signals, safety)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = {
            'success': True,
            'token_symbol': token_data.get('symbol', 'UNKNOWN'),
            'prediction': prediction_result,
            'signals': signals,
            'safety': safety,
            'recommendation': recommendation,
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        logger.info(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {token_data.get('symbol', 'UNKNOWN')} -> {prediction_result['prediction']} ({prediction_result['probability_percent']}%)")
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/health', methods=['GET'])
def health():
    """Health check –¥–ª—è Railway"""
    
    model_info = {}
    if model_artifacts:
        model_info = {
            'auc': model_artifacts['performance_metrics']['test_auc'],
            'f1': model_artifacts['performance_metrics']['test_f1'],
            'features_count': len(model_artifacts['feature_names'])
        }
    
    return jsonify({
        'status': 'healthy',
        'model_loaded': model_artifacts is not None,
        'model_info': model_info,
        'timestamp': pd.Timestamp.now().isoformat()
    })

@app.route('/model-info', methods=['GET'])
def model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    # –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    top_features = model_artifacts['feature_importance'].head(10).to_dict('records')
    
    return jsonify({
        'success': True,
        'model_type': model_artifacts.get('model_type', 'Unknown'),
        'training_approach': model_artifacts.get('training_approach', 'Unknown'),
        'performance_metrics': model_artifacts['performance_metrics'],
        'features_count': len(model_artifacts['feature_names']),
        'top_features': top_features,
        'all_features': model_artifacts['feature_names']
    })

@app.route('/example', methods=['GET'])
def example():
    """–ü—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è n8n"""
    
    example_data = {
        "symbol": "BONK",
        "market_cap": 2000000,
        "liquidity": 800000,
        "volume_1m": 100000,
        "buy_volume_1m": 65000,
        "sell_volume_1m": 35000,
        "buyers_green": 150,
        "buyers_blue": 30,
        "buyers_yellow": 20,
        "buyers_red": 15,
        "buyers_clown": 8,
        "buyers_sun": 3,
        "buyers_moon_half": 1,
        "buyers_moon_new": 2,
        "total_holders": 223,
        "top_10_percent": 35.0,
        "dev_current_balance_percent": 5.0,
        "security_no_mint": 1,
        "security_burnt": 1,
        "security_dev_sold": 0,
        "token_age_minutes": 180
    }
    
    return jsonify({
        'example_request': {
            'url': request.base_url.replace('/example', '/predict'),
            'method': 'POST',
            'headers': {
                'Content-Type': 'application/json'
            },
            'body': example_data
        },
        'required_fields': [
            'market_cap', 'liquidity', 'buyers_green', 'buyers_red'
        ],
        'optional_fields': [
            'symbol', 'volume_1m', 'buyers_blue', 'buyers_yellow',
            'buyers_clown', 'buyers_sun', 'buyers_moon_half', 'buyers_moon_new',
            'total_holders', 'top_10_percent', 'dev_current_balance_percent',
            'security_no_mint', 'security_burnt', 'security_dev_sold',
            'token_age_minutes'
        ]
    })

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'success': False,
        'error': 'Endpoint not found',
        'available_endpoints': ['/predict', '/health', '/model-info', '/example']
    }), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'success': False,
        'error': 'Internal server error'
    }), 500

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == '__main__':
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    load_model()
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è (Railway)
    port = int(os.environ.get('PORT', 5000))
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    app.run(host='0.0.0.0', port=port, debug=False)
