from flask import Flask, request, jsonify
from flask_cors import CORS
import re
import logging
import json
import os
from datetime import datetime
import sys
import warnings

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
warnings.filterwarnings('ignore')

# === –§–ò–ö–° –î–õ–Ø NUMPY._CORE –ü–†–û–ë–õ–ï–ú–´ ===
try:
    import numpy as np
    # –§–∏–∫—Å –¥–ª—è numpy._core –æ—à–∏–±–∫–∏
    if not hasattr(np, '_core'):
        try:
            import numpy.core as _core
            np._core = _core
            sys.modules['numpy._core'] = _core
        except:
            pass
    print("‚úÖ Numpy loaded successfully")
except Exception as e:
    print(f"‚ö†Ô∏è Numpy import issue: {e}")
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É –¥–ª—è numpy –µ—Å–ª–∏ —Å–æ–≤—Å–µ–º –Ω–µ —Ä–∞–±–æ—Ç–∞–µ—Ç
    class NumpyStub:
        def __init__(self):
            pass
        def array(self, x):
            return x
        def log1p(self, x):
            import math
            return math.log1p(x) if isinstance(x, (int, float)) else x
        def sqrt(self, x):
            import math
            return math.sqrt(x) if isinstance(x, (int, float)) else x
        def where(self, condition, x, y):
            return x if condition else y
        def cumsum(self, x):
            result = []
            total = 0
            for val in x:
                total += val
                result.append(total)
            return result
    np = NumpyStub()

# –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å pandas
try:
    import pandas as pd
    print("‚úÖ Pandas loaded successfully")
except Exception as e:
    print(f"‚ö†Ô∏è Pandas import issue: {e}")
    # –°–æ–∑–¥–∞–µ–º –∑–∞–≥–ª—É—à–∫—É –¥–ª—è pandas
    class PandasStub:
        def isna(self, x):
            return x is None or x == '' or str(x).lower() == 'nan'
        def DataFrame(self, data):
            return {'data': data}
    pd = PandasStub()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)

# =============================================================================
# –ó–ê–ì–õ–£–®–ö–ò –î–õ–Ø ML –ú–û–î–ï–õ–ò
# =============================================================================

MODEL_PATH = './'
model = None
scaler = None
label_encoders = None
feature_names = None
model_metadata = None
ensemble_weights = None

def load_ml_model():
    """–ü–æ–ø—ã—Ç–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ ML –º–æ–¥–µ–ª–∏ —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫"""
    global model, scaler, label_encoders, feature_names, model_metadata, ensemble_weights
    
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è –∏–º–ø–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å joblib
        try:
            import joblib
            print("‚úÖ Joblib imported successfully")
        except ImportError:
            print("‚ùå Joblib not available")
            return False
        
        logger.info("–ó–∞–≥—Ä—É–∂–∞–µ–º ML –º–æ–¥–µ–ª—å...")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã
        current_dir = os.getcwd()
        logger.info(f"–¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {current_dir}")
        
        try:
            files_in_root = [f for f in os.listdir('.') if f.endswith(('.pkl', '.json'))]
            logger.info(f"ML —Ñ–∞–π–ª—ã –≤ –∫–æ—Ä–Ω–µ: {files_in_root}")
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {e}")
            return False
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
        model_file = os.path.join(MODEL_PATH, 'memtoken_model_improved.pkl')
        if os.path.exists(model_file):
            try:
                size = os.path.getsize(model_file)
                logger.info(f"–ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏: {size} bytes")
                model = joblib.load(model_file)
                logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
                return False
        else:
            logger.warning(f"‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω: {model_file}")
            return False
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        try:
            scaler_file = os.path.join(MODEL_PATH, 'memtoken_scaler_improved.pkl')
            if os.path.exists(scaler_file):
                scaler = joblib.load(scaler_file)
                logger.info("‚úÖ –°–∫–µ–π–ª–µ—Ä –∑–∞–≥—Ä—É–∂–µ–Ω")
            
            encoders_file = os.path.join(MODEL_PATH, 'memtoken_encoders_improved.pkl')
            if os.path.exists(encoders_file):
                label_encoders = joblib.load(encoders_file)
                logger.info("‚úÖ –≠–Ω–∫–æ–¥–µ—Ä—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
            
            features_file = os.path.join(MODEL_PATH, 'memtoken_features_improved.pkl')
            if os.path.exists(features_file):
                feature_names = joblib.load(features_file)
                logger.info(f"‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ –∑–∞–≥—Ä—É–∂–µ–Ω—ã ({len(feature_names)} —à—Ç—É–∫)")
            
            metadata_file = os.path.join(MODEL_PATH, 'memtoken_model_metadata.json')
            if os.path.exists(metadata_file):
                with open(metadata_file, 'r') as f:
                    model_metadata = json.load(f)
                model_name = model_metadata.get('best_model_name', 'unknown')
                logger.info(f"‚úÖ –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã (–º–æ–¥–µ–ª—å: {model_name})")
        
        except Exception as e:
            logger.warning(f"–ù–µ–∫–æ—Ç–æ—Ä—ã–µ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {e}")
        
        # –§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞
        if model is not None:
            logger.info("üéâ ML –º–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ —Ä–∞–±–æ—Ç–µ!")
            return True
        else:
            logger.error("‚ùå –û—Å–Ω–æ–≤–Ω–∞—è –º–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
            return False
        
    except Exception as e:
        logger.error(f"‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        return False

# –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
ML_MODEL_LOADED = load_ml_model()

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –û–ë–†–ê–ë–û–¢–ö–ò –î–ê–ù–ù–´–•
# =============================================================================

def parse_string_number(value):
    """–ü–∞—Ä—Å–∏–Ω–≥ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö —á–∏—Å–µ–ª —Å K/M/B —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏"""
    if pd.isna(value) or value == '' or value == 'N/A':
        return 0
    
    if isinstance(value, (int, float)):
        return float(value)
    
    value = str(value).upper().replace(',', '').strip()
    value = re.sub(r'[^\d\.\-KMB]', '', value)
    
    if value == '' or value == '-':
        return 0
    
    try:
        if 'K' in value:
            return float(value.replace('K', '')) * 1_000
        elif 'M' in value:
            return float(value.replace('M', '')) * 1_000_000
        elif 'B' in value:
            return float(value.replace('B', '')) * 1_000_000_000
        else:
            return float(value)
    except:
        return 0

def parse_time_to_minutes(value):
    """–ü–∞—Ä—Å–∏–Ω–≥ –≤—Ä–µ–º–µ–Ω–∏ –≤ –º–∏–Ω—É—Ç—ã"""
    if pd.isna(value) or value == '' or value == 'N/A':
        return 0
    
    if isinstance(value, (int, float)):
        return float(value)
    
    total_minutes = 0
    value = str(value).lower().strip()
    
    try:
        # –î–Ω–∏
        days = re.findall(r'(\d+(?:\.\d+)?)d', value)
        if days:
            total_minutes += float(days[0]) * 1440
        
        # –ß–∞—Å—ã
        hours = re.findall(r'(\d+(?:\.\d+)?)h', value)
        if hours:
            total_minutes += float(hours[0]) * 60
        
        # –ú–∏–Ω—É—Ç—ã
        minutes = re.findall(r'(\d+(?:\.\d+)?)m(?!s)', value)
        if minutes:
            total_minutes += float(minutes[0])
        
        # –°–µ–∫—É–Ω–¥—ã
        seconds = re.findall(r'(\d+(?:\.\d+)?)s', value)
        if seconds:
            total_minutes += float(seconds[0]) / 60
            
        if total_minutes == 0:
            clean_value = re.sub(r'[^\d\.]', '', value)
            if clean_value:
                total_minutes = float(clean_value)
        
        return total_minutes
    except:
        return 0

def convert_input_to_features(token_data):
    """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –ø—Ä–∏–∑–Ω–∞–∫–∏ (–ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –í–ï–†–°–ò–Ø)"""
    try:
        features = {}
        logger.info(f"Processing token: {token_data.get('symbol', 'unknown')}")
        
        # –ë–∞–∑–æ–≤–∞—è –æ–±—Ä–∞–±–æ—Ç–∫–∞ —Ä—ã–Ω–æ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        market_cap_str = token_data.get('market_cap', '0')
        liquidity_str = token_data.get('liquidity', '0')
        ath_str = token_data.get('ath', '0')
        
        features['market_cap_numeric'] = parse_string_number(market_cap_str)
        features['liquidity_numeric'] = parse_string_number(liquidity_str)
        features['ath_numeric'] = parse_string_number(ath_str)
        
        logger.info(f"Market cap: {market_cap_str} -> {features['market_cap_numeric']}")
        logger.info(f"Liquidity: {liquidity_str} -> {features['liquidity_numeric']}")
        logger.info(f"ATH: {ath_str} -> {features['ath_numeric']}")
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—ã–±—Ä–æ—Å—ã
        features['market_cap_capped'] = min(features['market_cap_numeric'], 10_000_000)
        features['liquidity_capped'] = min(features['liquidity_numeric'], 1_000_000)
        features['ath_capped'] = min(features['ath_numeric'], 1_000_000)
        
        # –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Ä–µ–º–µ–Ω–∏
        token_age_str = token_data.get('token_age', '0')
        features['token_age_minutes'] = parse_time_to_minutes(token_age_str)
        features['token_age_hours'] = features['token_age_minutes'] / 60
        features['token_age_days'] = features['token_age_minutes'] / 1440
        
        logger.info(f"Token age: {token_age_str} -> {features['token_age_minutes']} minutes")
        
        # –ö–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –≤—Ä–µ–º–µ–Ω–∏
        features['is_very_new'] = 1 if features['token_age_minutes'] < 60 else 0
        features['is_new'] = 1 if features['token_age_minutes'] < 1440 else 0
        features['is_mature'] = 1 if features['token_age_minutes'] > 10080 else 0
        
        # –¢–æ—Ä–≥–æ–≤—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã - –ò–°–ü–†–ê–í–õ–ï–ù–ù–´–ï –ü–û–õ–Ø
        buy_volume_1m = float(token_data.get('buy_volume_1m', 0))
        sell_volume_1m = float(token_data.get('sell_volume_1m', 0))
        buy_volume_5m = float(token_data.get('buy_volume_5m', 0))
        sell_volume_5m = float(token_data.get('sell_volume_5m', 0))
        
        features['total_volume_1m'] = buy_volume_1m + sell_volume_1m
        features['total_volume_5m'] = buy_volume_5m + sell_volume_5m
        
        features['buy_sell_ratio_5m'] = buy_volume_5m / sell_volume_5m if sell_volume_5m > 0 else 0
        features['buy_pressure_5m'] = buy_volume_5m / features['total_volume_5m'] if features['total_volume_5m'] > 0 else 0
        
        logger.info(f"Buy volume 5m: {buy_volume_5m}, Sell volume 5m: {sell_volume_5m}")
        logger.info(f"Buy pressure 5m: {features['buy_pressure_5m']:.3f}")
        
        # –ü–æ–≤–µ–¥–µ–Ω—á–µ—Å–∫–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –°–¢–†–£–ö–¢–£–†–ê
        first_buyers = token_data.get('first_buyers', {})
        buyers_green = first_buyers.get('green', 0)
        buyers_blue = first_buyers.get('blue', 0)
        buyers_yellow = first_buyers.get('yellow', 0)
        buyers_red = first_buyers.get('red', 0)
        buyers_clown = first_buyers.get('clown', 0)
        buyers_moon_new = first_buyers.get('moon_new', 0)
        
        total_holders_emoji = buyers_green + buyers_blue + buyers_yellow + buyers_red
        total_snipers = buyers_clown + first_buyers.get('sun', 0) + first_buyers.get('moon_half', 0) + buyers_moon_new
        total_active = total_holders_emoji + total_snipers
        
        features['holders_diamond_hands'] = buyers_green / total_holders_emoji if total_holders_emoji > 0 else 0
        features['holders_paper_hands'] = buyers_red / total_holders_emoji if total_holders_emoji > 0 else 0
        features['trust_score'] = (buyers_green + buyers_clown) / (total_active + 1)
        features['distrust_score'] = (buyers_red + buyers_moon_new) / (total_active + 1)
        
        logger.info(f"First buyers - Green: {buyers_green}, Red: {buyers_red}, Total: {total_active}")
        logger.info(f"Trust score: {features['trust_score']:.3f}")
        
        # –†—ã–Ω–æ—á–Ω—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã
        features['liquidity_to_mcap_ratio'] = features['liquidity_capped'] / features['market_cap_capped'] if features['market_cap_capped'] > 0 else 0
        features['volume_to_liquidity_ratio'] = features['total_volume_5m'] / features['liquidity_capped'] if features['liquidity_capped'] > 0 else 0
        
        logger.info(f"Liquidity to mcap ratio: {features['liquidity_to_mcap_ratio']:.3f}")
        
        # –ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è –∫–∏—Ç–æ–≤ - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê
        top_10_holdings = token_data.get('top_10_holdings', [])
        if top_10_holdings and len(top_10_holdings) > 0:
            features['biggest_whale_percent'] = float(top_10_holdings[0]) if top_10_holdings[0] else 0
            features['top3_whales_percent'] = sum(float(x) for x in top_10_holdings[:3] if x)
        else:
            # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–± —á–µ—Ä–µ–∑ top_10_percent
            top_10_percent = token_data.get('top_10_percent', 0)
            features['biggest_whale_percent'] = float(top_10_percent) / 3 if top_10_percent else 0  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –æ—Ü–µ–Ω–∫–∞
            features['top3_whales_percent'] = float(top_10_percent) if top_10_percent else 0
        
        logger.info(f"Biggest whale: {features['biggest_whale_percent']:.1f}%")
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å - –ò–°–ü–†–ê–í–õ–ï–ù–ù–ê–Ø –õ–û–ì–ò–ö–ê
        security = token_data.get('security', {})
        security_score = 0
        security_score += 1 if security.get('no_mint', False) else 0
        security_score += 1 if security.get('blacklist', False) else 0
        security_score += 1 if security.get('burnt', False) else 0
        security_score += 1 if security.get('dev_sold', False) else 0
        security_score += 1 if security.get('dex_paid', False) else 0
        features['security_score'] = security_score
        
        logger.info(f"Security score: {security_score}/5")
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
        features['total_holders'] = float(token_data.get('total_holders', 0))
        features['volume_per_holder'] = features['total_volume_5m'] / features['total_holders'] if features['total_holders'] > 0 else 0
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        buys_5m = float(token_data.get('buys_5m', 0))
        sells_5m = float(token_data.get('sells_5m', 0))
        features['buy_sell_tx_ratio'] = buys_5m / sells_5m if sells_5m > 0 else 0
        features['total_transactions_5m'] = buys_5m + sells_5m
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ volatility
        ath_change_percent = token_data.get('ath_change_percent', 0)
        features['ath_change_percent'] = float(ath_change_percent) if ath_change_percent else 0
        features['is_near_ath'] = 1 if abs(features['ath_change_percent']) < 10 else 0
        
        logger.info(f"Generated {len(features)} features")
        
        return features
        
    except Exception as e:
        logger.error(f"Error converting features: {e}")
        return {}

# =============================================================================
# –§–£–ù–ö–¶–ò–ò –ü–†–ï–î–°–ö–ê–ó–ê–ù–ò–Ø
# =============================================================================

def ml_predict(features):
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å ML –º–æ–¥–µ–ª—å—é –∏–ª–∏ fallback –Ω–∞ –ø—Ä–∞–≤–∏–ª–∞"""
    try:
        # –ï—Å–ª–∏ ML –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –ø—ã—Ç–∞–µ–º—Å—è –µ—ë –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å
        if ML_MODEL_LOADED and model is not None:
            try:
                # –ü—Ä–æ—Å—Ç–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –±–µ–∑ —Å–ª–æ–∂–Ω—ã—Ö –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–π
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
                basic_features = [
                    features.get('market_cap_capped', 0),
                    features.get('liquidity_capped', 0),
                    features.get('token_age_minutes', 0),
                    features.get('buy_pressure_5m', 0),
                    features.get('biggest_whale_percent', 0),
                    features.get('trust_score', 0),
                    features.get('security_score', 0),
                    features.get('liquidity_to_mcap_ratio', 0)
                ]
                
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–Ω–∞—á–µ–Ω–∏—è
                X = [max(0, min(1000000, float(x))) for x in basic_features]
                
                if hasattr(model, 'predict_proba'):
                    # –ü—ã—Ç–∞–µ–º—Å—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞—Ç—å –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
                    try:
                        probability = model.predict_proba([X])[0][1]
                    except:
                        # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∞–µ—Ç—Å—è, –∏—Å–ø–æ–ª—å–∑—É–µ–º predict
                        prediction = model.predict([X])[0]
                        probability = 0.7 if prediction == 1 else 0.3
                else:
                    prediction = model.predict([X])[0]
                    probability = 0.7 if prediction == 1 else 0.3
                
                prediction = 1 if probability > 0.5 else 0
                
                # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
                if probability >= 0.75:
                    recommendation = "üöÄ STRONG BUY"
                elif probability >= 0.65:
                    recommendation = "‚úÖ BUY"
                elif probability >= 0.55:
                    recommendation = "‚öñÔ∏è CONSIDER"
                elif probability >= 0.45:
                    recommendation = "‚ö†Ô∏è CAUTION"
                else:
                    recommendation = "‚ùå AVOID"
                
                return {
                    'probability': float(probability),
                    'prediction': int(prediction),
                    'recommendation': recommendation,
                    'confidence_interval': (max(0, probability - 0.1), min(1, probability + 0.1)),
                    'model_info': {
                        'model_name': model_metadata.get('best_model_name', 'ML Model') if model_metadata else 'ML Model',
                        'model_auc': model_metadata.get('test_auc', 0.75) if model_metadata else 0.75,
                        'features_used': len(basic_features),
                        'is_ensemble': False
                    }
                }
                
            except Exception as e:
                logger.error(f"ML prediction failed: {e}")
                # Fallback –Ω–∞ –ø—Ä–æ—Å—Ç—ã–µ –ø—Ä–∞–≤–∏–ª–∞
                pass
        
        # –ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∞–≤–∏–ª–∞ (fallback)
        return simple_predict(features)
        
    except Exception as e:
        logger.error(f"Error in ml_predict: {e}")
        return simple_predict(features)

def simple_predict(features):
    """–£–ª—É—á—à–µ–Ω–Ω—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è"""
    try:
        score = 0.5  # –ë–∞–∑–æ–≤–∞—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        
        # –í–æ–∑—Ä–∞—Å—Ç —Ç–æ–∫–µ–Ω–∞
        age_minutes = features.get('token_age_minutes', 0)
        if age_minutes < 60:
            score -= 0.1  # –û—á–µ–Ω—å –Ω–æ–≤—ã–µ —Ç–æ–∫–µ–Ω—ã —Ä–∏—Å–∫–æ–≤–∞–Ω–Ω–µ–µ (–Ω–æ –Ω–µ —Ç–∞–∫ —Å–∏–ª—å–Ω–æ)
        elif 60 <= age_minutes <= 1440:
            score += 0.1   # –û–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –≤–æ–∑—Ä–∞—Å—Ç
        elif age_minutes > 10080:
            score -= 0.05  # –°—Ç–∞—Ä—ã–µ —Ç–æ–∫–µ–Ω—ã –º–µ–Ω–µ–µ –∞–∫—Ç–∏–≤–Ω—ã
        
        # –î–∞–≤–ª–µ–Ω–∏–µ –ø–æ–∫—É–ø–æ–∫
        buy_pressure = features.get('buy_pressure_5m', 0)
        if buy_pressure > 0.65:
            score += 0.2   # –°–∏–ª—å–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ –ø–æ–∫—É–ø–æ–∫
        elif buy_pressure > 0.55:
            score += 0.1   # –£–º–µ—Ä–µ–Ω–Ω–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ
        elif buy_pressure < 0.35:
            score -= 0.2   # –°–ª–∞–±–æ–µ –¥–∞–≤–ª–µ–Ω–∏–µ
        
        # –ö–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è –∫–∏—Ç–æ–≤
        whale_percent = features.get('biggest_whale_percent', 0)
        if whale_percent > 25:
            score -= 0.25  # –û—á–µ–Ω—å –æ–ø–∞—Å–Ω–∞—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è
        elif whale_percent > 15:
            score -= 0.15  # –û–ø–∞—Å–Ω–∞—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è
        elif whale_percent < 8:
            score += 0.1   # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—è
        
        # Trust score
        trust = features.get('trust_score', 0)
        if trust > 0.7:
            score += 0.15  # –í—ã—Å–æ–∫–æ–µ –¥–æ–≤–µ—Ä–∏–µ
        elif trust > 0.5:
            score += 0.05  # –£–º–µ—Ä–µ–Ω–Ω–æ–µ –¥–æ–≤–µ—Ä–∏–µ
        elif trust < 0.2:
            score -= 0.15  # –ù–∏–∑–∫–æ–µ –¥–æ–≤–µ—Ä–∏–µ
        
        # –õ–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å –∫ market cap
        liq_mcap_ratio = features.get('liquidity_to_mcap_ratio', 0)
        if liq_mcap_ratio > 0.6:
            score += 0.1   # –û—Ç–ª–∏—á–Ω–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
        elif liq_mcap_ratio > 0.3:
            score += 0.05  # –•–æ—Ä–æ—à–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
        elif liq_mcap_ratio < 0.15:
            score -= 0.15  # –ü–ª–æ—Ö–∞—è –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
        
        # –ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        security_score = features.get('security_score', 0)
        if security_score >= 4:
            score += 0.1   # –í—ã—Å–æ–∫–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        elif security_score >= 3:
            score += 0.05  # –°—Ä–µ–¥–Ω—è—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        elif security_score <= 1:
            score -= 0.2   # –ù–∏–∑–∫–∞—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        
        # –†–∞–∑–º–µ—Ä market cap (–ø—Ä–µ–¥–ø–æ—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω–∏–µ —Ä–∞–∑–º–µ—Ä—ã)
        mcap = features.get('market_cap_capped', 0)
        if 50000 <= mcap <= 500000:  # Sweet spot
            score += 0.05
        elif mcap > 5000000:         # –°–ª–∏—à–∫–æ–º –±–æ–ª—å—à–∏–µ
            score -= 0.05
        elif mcap < 10000:           # –°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ
            score -= 0.1
        
        # –ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
        total_tx = features.get('total_transactions_5m', 0)
        if total_tx > 500:  # –í—ã—Å–æ–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            score += 0.05
        elif total_tx < 50:  # –ù–∏–∑–∫–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            score -= 0.1
        
        # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ –ø–æ–∫—É–ø–æ–∫ –∫ –ø—Ä–æ–¥–∞–∂–∞–º –ø–æ —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏—è–º
        tx_ratio = features.get('buy_sell_tx_ratio', 0)
        if tx_ratio > 1.2:  # –ë–æ–ª—å—à–µ –ø–æ–∫—É–ø–∞—Ç–µ–ª—å—Å–∫–∏—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
            score += 0.05
        elif tx_ratio < 0.8:  # –ë–æ–ª—å—à–µ –ø—Ä–æ–¥–∞–∂–Ω—ã—Ö —Ç—Ä–∞–Ω–∑–∞–∫—Ü–∏–π
            score -= 0.05
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å
        probability = max(0.05, min(0.95, score))
        prediction = 1 if probability > 0.5 else 0
        
        # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è
        if probability >= 0.8:
            recommendation = "üî• VERY STRONG BUY"
        elif probability >= 0.7:
            recommendation = "üöÄ STRONG BUY" 
        elif probability >= 0.6:
            recommendation = "‚úÖ BUY"
        elif probability >= 0.5:
            recommendation = "‚öñÔ∏è CONSIDER"
        elif probability >= 0.4:
            recommendation = "‚ö†Ô∏è CAUTION"
        elif probability >= 0.3:
            recommendation = "‚ùå AVOID"
        else:
            recommendation = "üö´ STRONG AVOID"
        
        return {
            'probability': float(probability),
            'prediction': int(prediction),
            'recommendation': recommendation,
            'confidence_interval': (max(0, probability - 0.1), min(1, probability + 0.1)),
            'model_info': {
                'model_name': 'Advanced Rules',
                'model_auc': 0.68,
                'features_used': len(features),
                'is_ensemble': False
            },
            'key_factors': {
                'age_minutes': age_minutes,
                'buy_pressure_5m': buy_pressure,
                'biggest_whale_percent': whale_percent,
                'trust_score': trust,
                'security_score': security_score,
                'liquidity_to_mcap_ratio': liq_mcap_ratio,
                'market_cap': mcap,
                'total_transactions_5m': total_tx,
                'buy_sell_tx_ratio': tx_ratio
            }
        }
        
    except Exception as e:
        logger.error(f"Error in simple prediction: {e}")
        return {
            'probability': 0.5,
            'prediction': 0,
            'recommendation': "‚ùì ERROR",
            'confidence_interval': (0.0, 1.0),
            'model_info': {
                'model_name': 'Error',
                'model_auc': 0.0,
                'features_used': 0,
                'is_ensemble': False
            },
            'error': str(e)
        }

# =============================================================================
# API ENDPOINTS
# =============================================================================

@app.route('/', methods=['GET'])
def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è API"""
    return jsonify({
        'status': 'healthy',
        'message': 'Memtoken Prediction API is running',
        'timestamp': datetime.now().isoformat(),
        'version': '1.1.0',
        'ml_model_loaded': ML_MODEL_LOADED,
        'model_info': {
            'model_name': model_metadata.get('best_model_name', 'Advanced Rules') if model_metadata else 'Advanced Rules',
            'model_auc': model_metadata.get('test_auc', 0.68) if model_metadata else 0.68,
            'features_count': len(feature_names) if feature_names else 25,
            'components_loaded': {
                'model': model is not None,
                'scaler': scaler is not None,
                'encoders': label_encoders is not None,
                'features': feature_names is not None,
                'metadata': model_metadata is not None
            }
        }
    })

@app.route('/predict', methods=['POST'])
def predict():
    """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        logger.info(f"Received prediction request for token: {data.get('symbol', 'unknown')}")
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –≤ –ø—Ä–∏–∑–Ω–∞–∫–∏
        features = convert_input_to_features(data)
        
        if not features:
            return jsonify({'error': 'Failed to extract features from token data'}), 400
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        result = ml_predict(features)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–æ–∫–µ–Ω–µ
        result['token_info'] = {
            'symbol': data.get('symbol', ''),
            'name': data.get('name', ''),
            'contract_address': data.get('contract_address', ''),
            'market_cap': data.get('market_cap', ''),
            'liquidity': data.get('liquidity', ''),
            'token_age': data.get('token_age', ''),
            'timestamp': datetime.now().isoformat()
        }
        
        logger.info(f"Prediction completed: {result['recommendation']} ({result['probability']:.3f})")
        
        return jsonify(result)
        
    except Exception as e:
        logger.error(f"Error in predict endpoint: {e}")
        return jsonify({
            'error': 'Internal server error',
            'message': str(e)
        }), 500

@app.route('/predict/batch', methods=['POST'])
def predict_batch():
    """–ü–∞–∫–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ"""
    try:
        data = request.get_json()
        
        if not data or not isinstance(data, list):
            return jsonify({'error': 'Data should be a list of token objects'}), 400
        
        if len(data) > 100:
            return jsonify({'error': 'Batch size cannot exceed 100 tokens'}), 400
        
        results = []
        
        for i, token_data in enumerate(data):
            try:
                features = convert_input_to_features(token_data)
                result = ml_predict(features)
                
                result['token_info'] = {
                    'symbol': token_data.get('symbol', ''),
                    'name': token_data.get('name', ''),
                    'batch_index': i
                }
                
                results.append(result)
                
            except Exception as e:
                results.append({
                    'error': f'Error processing token {i}',
                    'message': str(e),
                    'token_info': {'symbol': token_data.get('symbol', ''), 'batch_index': i}
                })
        
        successful_predictions = [r for r in results if 'error' not in r]
        avg_probability = sum(r['probability'] for r in successful_predictions) / len(successful_predictions) if successful_predictions else 0
        
        return jsonify({
            'results': results,
            'batch_stats': {
                'total_tokens': len(data),
                'successful_predictions': len(successful_predictions),
                'average_probability': avg_probability,
                'timestamp': datetime.now().isoformat()
            }
        })
        
    except Exception as e:
        return jsonify({'error': 'Internal server error', 'message': str(e)}), 500

@app.route('/debug/features', methods=['POST'])
def debug_features():
    """–û—Ç–ª–∞–¥–∫–∞: –ø–æ–∫–∞–∑–∞—Ç—å –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏"""
    try:
        data = request.get_json()
        
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        features = convert_input_to_features(data)
        
        return jsonify({
            'input_data': data,
            'extracted_features': features,
            'feature_count': len(features),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({'error': 'Internal server error', 'message': str(e)}), 500

@app.route('/debug/files', methods=['GET'])
def debug_files():
    """–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Ñ–∞–π–ª–æ–≤"""
    try:
        files_info = {
            'current_directory': os.getcwd(),
            'all_files': os.listdir('.'),
            'pkl_files': [f for f in os.listdir('.') if f.endswith('.pkl')],
            'json_files': [f for f in os.listdir('.') if f.endswith('.json')]
        }
        return jsonify(files_info)
    except Exception as e:
        return jsonify({'error': str(e)}), 500

@app.route('/test', methods=['GET'])
def test_with_sample():
    """–¢–µ—Å—Ç —Å –ø—Ä–∏–º–µ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö"""
    sample_data = {
        "symbol": "TEST",
        "name": "Test Token",
        "contract_address": "test123",
        "token_age": "1h 30m",
        "market_cap": "50K",
        "liquidity": "35K",
        "ath": "75K",
        "buy_volume_5m": 15000,
        "sell_volume_5m": 12000,
        "buys_5m": 45,
        "sells_5m": 35,
        "first_buyers": {
            "green": 8,
            "blue": 5,
            "yellow": 3,
            "red": 12,
            "clown": 1,
            "moon_new": 2
        },
        "top_10_holdings": [15.5, 8.2, 6.1, 4.3, 3.8],
        "total_holders": 150,
        "security": {
            "no_mint": True,
            "blacklist": True,
            "burnt": True,
            "dev_sold": False,
            "dex_paid": True
        }
    }
    
    try:
        features = convert_input_to_features(sample_data)
        result = ml_predict(features)
        
        return jsonify({
            'test_data': sample_data,
            'features': features,
            'prediction': result,
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        return jsonify({'error': str(e)}), 500

# =============================================================================
# ERROR HANDLERS
# =============================================================================

@app.errorhandler(404)
def not_found(error):
    return jsonify({'error': 'Endpoint not found'}), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({'error': 'Internal server error'}), 500

# =============================================================================
# MAIN
# =============================================================================

if __name__ == '__main__':
    port = int(os.environ.get('PORT', 5000))
    debug = os.environ.get('DEBUG', 'False').lower() == 'true'
    
    print("üöÄ Starting Memtoken Prediction API...")
    print(f"üìä ML Model loaded: {'‚úÖ' if ML_MODEL_LOADED else '‚ùå'}")
    if ML_MODEL_LOADED and model_metadata:
        print(f"üéØ Model: {model_metadata.get('best_model_name', 'Unknown')}")
        print(f"üìà AUC: {model_metadata.get('test_auc', 0):.4f}")
        print(f"üîß Features: {len(feature_names) if feature_names else 0}")
    else:
        print("‚ö†Ô∏è  Using Advanced Rules (AUC ~0.68)")
    
    app.run(host='0.0.0.0', port=port, debug=debug)
