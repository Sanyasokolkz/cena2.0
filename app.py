# app.py - API –¥–ª—è Railway + n8n —Å–æ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ JSON –¥–∞–Ω–Ω—ã–º–∏
import os
import pickle
import pandas as pd
import numpy as np
import re
from flask import Flask, request, jsonify
import logging

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = Flask(__name__)

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è –º–æ–¥–µ–ª–∏
model_artifacts = None

def load_model():
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
    global model_artifacts
    
    # –°–ø–∏—Å–æ–∫ –≤–æ–∑–º–æ–∂–Ω—ã—Ö –ø—É—Ç–µ–π –∫ –º–æ–¥–µ–ª–∏
    possible_paths = [
        'solana_token_xgboost_model.pkl',
        './solana_token_xgboost_model.pkl',
        '/app/solana_token_xgboost_model.pkl',
        os.path.join(os.getcwd(), 'solana_token_xgboost_model.pkl')
    ]
    
    logger.info(f"üîç –¢–µ–∫—É—â–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {os.getcwd()}")
    logger.info(f"üìÅ –§–∞–π–ª—ã –≤ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏: {os.listdir('.')}")
    
    model_file = None
    for path in possible_paths:
        logger.info(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Ç—å: {path}")
        if os.path.exists(path):
            model_file = path
            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω —Ñ–∞–π–ª –º–æ–¥–µ–ª–∏: {path}")
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞
            file_size = os.path.getsize(path)
            logger.info(f"üìè –†–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞: {file_size} bytes ({file_size/1024/1024:.2f} MB)")
            break
        else:
            logger.info(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {path}")
    
    if not model_file:
        logger.error("‚ùå –§–∞–π–ª –º–æ–¥–µ–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω –Ω–∏ –≤ –æ–¥–Ω–æ–º –∏–∑ –ø—É—Ç–µ–π!")
        logger.error("üìÇ –î–æ—Å—Ç—É–ø–Ω—ã–µ —Ñ–∞–π–ª—ã:")
        for file in os.listdir('.'):
            logger.error(f"   - {file}")
        return False
    
    try:
        logger.info("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏...")
        
        # –ü—Ä–æ–±—É–µ–º —Ä–∞–∑–Ω—ã–µ —Å–ø–æ—Å–æ–±—ã –∑–∞–≥—Ä—É–∑–∫–∏
        try:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π —Å–ø–æ—Å–æ–±
            with open(model_file, 'rb') as f:
                model_artifacts = pickle.load(f)
            logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–º —Å–ø–æ—Å–æ–±–æ–º")
        except Exception as e1:
            logger.warning(f"‚ö†Ô∏è –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –Ω–µ —É–¥–∞–ª–∞—Å—å: {e1}")
            try:
                # –ü—Ä–æ–±—É–µ–º —Å joblib
                import joblib
                model_artifacts = joblib.load(model_file)
                logger.info("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —á–µ—Ä–µ–∑ joblib")
            except Exception as e2:
                logger.error(f"‚ùå –ó–∞–≥—Ä—É–∑–∫–∞ —á–µ—Ä–µ–∑ joblib –Ω–µ —É–¥–∞–ª–∞—Å—å: {e2}")
                raise e1  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—É—é –æ—à–∏–±–∫—É
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –º–æ–¥–µ–ª–∏
        if not isinstance(model_artifacts, dict):
            logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π —Ç–∏–ø –º–æ–¥–µ–ª–∏: {type(model_artifacts)}")
            return False
            
        required_keys = ['model', 'feature_names', 'imputer', 'performance_metrics']
        missing_keys = [key for key in required_keys if key not in model_artifacts]
        
        if missing_keys:
            logger.error(f"‚ùå –í –º–æ–¥–µ–ª–∏ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∫–ª—é—á–∏: {missing_keys}")
            logger.error(f"üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–ª—é—á–∏: {list(model_artifacts.keys())}")
            return False
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
        logger.info(f"üîç –¢–∏–ø –º–æ–¥–µ–ª–∏: {type(model_artifacts['model'])}")
        logger.info(f"üîç –¢–∏–ø –∏–º–ø—É—Ç–µ—Ä–∞: {type(model_artifacts['imputer'])}")
        logger.info(f"üîç –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(model_artifacts['feature_names'])}")
        
        logger.info(f"‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
        logger.info(f"üìä AUC: {model_artifacts['performance_metrics']['test_auc']:.4f}")
        logger.info(f"üî¢ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤: {len(model_artifacts['feature_names'])}")
        
        return True
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
        logger.error(f"‚ùå –¢–∏–ø –æ—à–∏–±–∫–∏: {type(e).__name__}")
        import traceback
        logger.error(f"‚ùå –¢—Ä–µ–π—Å–±–µ–∫: {traceback.format_exc()}")
        return False

def parse_value_with_suffix(value_str):
    """–ü–∞—Ä—Å–∏—Ç —Å—Ç—Ä–æ–∫–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è —Å —Å—É—Ñ—Ñ–∏–∫—Å–∞–º–∏ K, M, B"""
    if not value_str or value_str is None:
        return 0
    
    if isinstance(value_str, (int, float)):
        return float(value_str)
    
    value_str = str(value_str).replace(',', '').replace(' ', '').strip()
    
    if value_str.endswith('K'):
        return float(value_str[:-1]) * 1000
    elif value_str.endswith('M'):
        return float(value_str[:-1]) * 1000000
    elif value_str.endswith('B'):
        return float(value_str[:-1]) * 1000000000
    else:
        try:
            return float(value_str)
        except:
            return 0

def parse_token_age_minutes(token_age_str):
    """–ü–∞—Ä—Å–∏—Ç –≤–æ–∑—Ä–∞—Å—Ç —Ç–æ–∫–µ–Ω–∞ –≤ –º–∏–Ω—É—Ç—ã"""
    if not token_age_str:
        return 0
    
    # –ò–∑–≤–ª–µ–∫–∞–µ–º —á–∏—Å–ª–æ –∏ –µ–¥–∏–Ω–∏—Ü—É –∏–∑–º–µ—Ä–µ–Ω–∏—è
    match = re.match(r'(\d+)([mhd]?)', str(token_age_str))
    if not match:
        return 0
    
    value = int(match.group(1))
    unit = match.group(2)
    
    if unit == 'm' or unit == '':  # –º–∏–Ω—É—Ç—ã
        return value
    elif unit == 'h':  # —á–∞—Å—ã
        return value * 60
    elif unit == 'd':  # –¥–Ω–∏
        return value * 60 * 24
    else:
        return value

def process_token_data(token_json):
    """–û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ JSON –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞"""
    
    try:
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        symbol = token_json.get('symbol', 'UNKNOWN')
        token_age_minutes = parse_token_age_minutes(token_json.get('token_age'))
        
        # –†—ã–Ω–æ—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        market_cap = parse_value_with_suffix(token_json.get('market_cap'))
        liquidity = parse_value_with_suffix(token_json.get('liquidity'))
        ath = parse_value_with_suffix(token_json.get('ath'))
        sol_pooled = token_json.get('sol_pooled') or 0
        
        # –û–±—ä–µ–º—ã —Ç–æ—Ä–≥–æ–≤
        volume_1m = token_json.get('volume_1m', 0)
        buy_volume_1m = token_json.get('buy_volume_1m', 0)
        sell_volume_1m = token_json.get('sell_volume_1m', 0)
        buys_1m = token_json.get('buys_1m', 0)
        sells_1m = token_json.get('sells_1m', 0)
        
        volume_5m = token_json.get('volume_5m', 0)
        buy_volume_5m = token_json.get('buy_volume_5m', 0)
        sell_volume_5m = token_json.get('sell_volume_5m', 0)
        buys_5m = token_json.get('buys_5m', 0)
        sells_5m = token_json.get('sells_5m', 0)
        
        # –ü–æ–∫—É–ø–∞—Ç–µ–ª–∏ (–∏–∑ first_buyers)
        first_buyers = token_json.get('first_buyers', {})
        buyers_green = first_buyers.get('green', 0)
        buyers_blue = first_buyers.get('blue', 0)
        buyers_yellow = first_buyers.get('yellow', 0)
        buyers_red = first_buyers.get('red', 0)
        buyers_clown = first_buyers.get('clown', 0)
        buyers_sun = first_buyers.get('sun', 0)
        buyers_moon_half = first_buyers.get('moon_half', 0)
        buyers_moon_new = first_buyers.get('moon_new', 0)
        
        # Current/Initial ratio
        ratio_data = token_json.get('current_initial_ratio', {})
        current_ratio = ratio_data.get('current', 0)
        initial_ratio = ratio_data.get('initial', 0)
        
        # –î–µ—Ä–∂–∞—Ç–µ–ª–∏
        total_holders = token_json.get('total_holders', 0)
        freshies_1d_percent = token_json.get('freshies_1d_percent', 0)
        freshies_7d_percent = token_json.get('freshies_7d_percent', 0)
        top_10_percent = token_json.get('top_10_percent', 0)
        
        # Top 10 holdings - –±–µ—Ä–µ–º –ø–µ—Ä–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ
        top_10_holdings_list = token_json.get('top_10_holdings', [])
        top_10_holdings = top_10_holdings_list[0] if top_10_holdings_list else 0
        
        # Dev –¥–∞–Ω–Ω—ã–µ
        dev_current_balance_percent = token_json.get('dev_current_balance_percent', 0)
        dev_sol_balance = token_json.get('dev_sol_balance', 0)
        
        # Security –¥–∞–Ω–Ω—ã–µ
        security = token_json.get('security', {})
        security_no_mint = 1 if security.get('no_mint') else 0
        security_blacklist = 1 if security.get('blacklist') else 0
        security_burnt = 1 if security.get('burnt') else 0
        security_dev_sold = 1 if security.get('dev_sold') else 0
        security_dex_paid = 1 if security.get('dex_paid') else 0
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏
        processed_data = {
            'symbol': symbol,
            'token_age_minutes': token_age_minutes,
            'market_cap': market_cap,
            'liquidity': liquidity,
            'sol_pooled': sol_pooled,
            'ath': ath,
            'volume_1m': volume_1m,
            'buy_volume_1m': buy_volume_1m,
            'sell_volume_1m': sell_volume_1m,
            'buys_1m': buys_1m,
            'sells_1m': sells_1m,
            'volume_5m': volume_5m,
            'buy_volume_5m': buy_volume_5m,
            'sell_volume_5m': sell_volume_5m,
            'buys_5m': buys_5m,
            'sells_5m': sells_5m,
            'buyers_green': buyers_green,
            'buyers_blue': buyers_blue,
            'buyers_yellow': buyers_yellow,
            'buyers_red': buyers_red,
            'buyers_clown': buyers_clown,
            'buyers_sun': buyers_sun,
            'buyers_moon_half': buyers_moon_half,
            'buyers_moon_new': buyers_moon_new,
            'current_ratio': current_ratio,
            'initial_ratio': initial_ratio,
            'total_holders': total_holders,
            'freshies_1d_percent': freshies_1d_percent,
            'freshies_7d_percent': freshies_7d_percent,
            'top_10_percent': top_10_percent,
            'top_10_holdings': top_10_holdings,
            'dev_current_balance_percent': dev_current_balance_percent,
            'dev_sol_balance': dev_sol_balance,
            'security_no_mint': security_no_mint,
            'security_blacklist': security_blacklist,
            'security_burnt': security_burnt,
            'security_dev_sold': security_dev_sold,
            'security_dex_paid': security_dex_paid
        }
        
        logger.info(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö —É—Å–ø–µ—à–Ω–∞ –¥–ª—è {symbol}: MC=${market_cap:,.0f}, Liq=${liquidity:,.0f}")
        return processed_data
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
        raise ValueError(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö —Ç–æ–∫–µ–Ω–∞: {e}")

def predict_token_success(token_data):
    """–§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ—Å—Ç–∏ —Ç–æ–∫–µ–Ω–∞"""
    
    if model_artifacts is None:
        raise ValueError("–ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
    
    try:
        # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö
        df_new = pd.DataFrame([token_data])
        
        # –î–æ–±–∞–≤–ª—è–µ–º –Ω–µ–¥–æ—Å—Ç–∞—é—â–∏–µ —Å—Ç–æ–ª–±—Ü—ã —Å –Ω—É–ª–µ–≤—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        for col in model_artifacts['feature_names']:
            if col not in df_new.columns:
                df_new[col] = 0
        
        # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º —Å—Ç–æ–ª–±—Ü—ã
        df_new = df_new[model_artifacts['feature_names']]
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –∏–º–ø—É—Ç–µ—Ä
        df_imputed = pd.DataFrame(
            model_artifacts['imputer'].transform(df_new), 
            columns=model_artifacts['feature_names']
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        prediction = model_artifacts['model'].predict(df_imputed)[0]
        probability = model_artifacts['model'].predict_proba(df_imputed)[0, 1]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
        confidence_score = abs(probability - 0.5) * 2
        if confidence_score > 0.8:
            confidence_level = "very_high"
        elif confidence_score > 0.6:
            confidence_level = "high"
        elif confidence_score > 0.4:
            confidence_level = "medium"
        else:
            confidence_level = "low"
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        result = {
            'prediction': 'success' if prediction == 1 else 'fail',
            'binary_prediction': int(prediction),
            'probability': round(probability, 4),
            'probability_percent': round(probability * 100, 1),
            'confidence_score': round(confidence_score, 4),
            'confidence_level': confidence_level,
            'expected_pnl': 'PNL >= 2x' if prediction == 1 else 'PNL < 2x'
        }
        
        return result
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
        raise

def analyze_token_signals(token_data):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–∏–≥–Ω–∞–ª—ã —Ç–æ–∫–µ–Ω–∞"""
    
    # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã (—Ö–æ–ª–¥—è—Ç –∏ –¥–æ–∫—É–ø–∞—é—Ç)
    positive = (token_data.get('buyers_green', 0) + 
                token_data.get('buyers_blue', 0) + 
                token_data.get('buyers_clown', 0) + 
                token_data.get('buyers_sun', 0))
    
    # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã (–ø—Ä–æ–¥–∞–ª–∏ –ø–æ–ª–Ω–æ—Å—Ç—å—é)
    negative = (token_data.get('buyers_red', 0) + 
                token_data.get('buyers_moon_new', 0))
    
    # –°–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ
    ratio = positive / (negative + 1)
    
    if ratio > 3:
        status = "very_good"
    elif ratio > 1.5:
        status = "good"
    elif ratio > 0.8:
        status = "medium"
    else:
        status = "bad"
    
    return {
        'positive_signals': positive,
        'negative_signals': negative,
        'signal_ratio': round(ratio, 2),
        'signal_status': status
    }

def check_token_safety(token_data):
    """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å —Ç–æ–∫–µ–Ω–∞"""
    
    safety_score = 0
    issues = []
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–Ω—Ü–µ–Ω—Ç—Ä–∞—Ü–∏—é
    top10 = token_data.get('top_10_percent', 0)
    if top10 <= 70:
        safety_score += 1
    else:
        issues.append(f"high_concentration_{top10}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–∞
    dev_percent = token_data.get('dev_current_balance_percent', 0)
    if dev_percent <= 20:
        safety_score += 1
    else:
        issues.append(f"dev_holds_much_{dev_percent}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–∏–∫–≤–∏–¥–Ω–æ—Å—Ç—å
    liquidity = token_data.get('liquidity', 0)
    if liquidity >= 100000:
        safety_score += 1
    else:
        issues.append(f"low_liquidity_{liquidity}")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
    if token_data.get('security_no_mint', 0):
        safety_score += 1
    else:
        issues.append("mint_not_disabled")
        
    if token_data.get('security_burnt', 0):
        safety_score += 1
    else:
        issues.append("tokens_not_burnt")
    
    return {
        'safety_score': safety_score,
        'max_safety_score': 5,
        'safety_percentage': round((safety_score / 5) * 100),
        'safety_issues': issues,
        'is_safe': safety_score >= 3
    }

def get_recommendation(prediction_result, signals, safety):
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—É—é —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é"""
    
    probability = prediction_result['probability']
    safety_score = safety['safety_score']
    
    if probability >= 0.7 and safety_score >= 4:
        return {
            'recommendation': 'BUY',
            'risk_level': 'low',
            'reason': 'excellent_token'
        }
    elif probability >= 0.6 and safety_score >= 3:
        return {
            'recommendation': 'CONSIDER',
            'risk_level': 'medium',
            'reason': 'good_potential'
        }
    elif probability >= 0.5 and safety_score >= 2:
        return {
            'recommendation': 'CAUTION',
            'risk_level': 'medium_high',
            'reason': 'moderate_risk'
        }
    else:
        return {
            'recommendation': 'AVOID',
            'risk_level': 'high',
            'reason': 'high_risk'
        }

# =============================================================================
# API ENDPOINTS
# =============================================================================

@app.route('/', methods=['GET'])
def home():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ API"""
    return jsonify({
        'service': 'Solana Token Predictor API',
        'status': 'online',
        'model_loaded': model_artifacts is not None,
        'endpoints': {
            'predict': '/predict [POST]',
            'predict_batch': '/predict-batch [POST]',
            'health': '/health [GET]',
            'model_info': '/model-info [GET]',
            'reload_model': '/reload-model [POST]',
            'example': '/example [GET]'
        }
    })

@app.route('/predict', methods=['POST'])
def predict():
    """–û—Å–Ω–æ–≤–Ω–æ–π endpoint –¥–ª—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –æ–¥–Ω–æ–≥–æ —Ç–æ–∫–µ–Ω–∞"""
    
    # –ü–æ–¥—Ä–æ–±–Ω–∞—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ —Å–æ—Å—Ç–æ—è–Ω–∏—è –º–æ–¥–µ–ª–∏
    if model_artifacts is None:
        logger.error("‚ùå –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ /predict")
        return jsonify({
            'success': False,
            'error': 'Model not loaded',
            'debug_info': {
                'current_directory': os.getcwd(),
                'files_in_directory': os.listdir('.'),
                'model_artifacts_status': 'None'
            }
        }), 500
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Content-Type must be application/json'
            }), 400
        
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ –ø—Ä–∏—à–ª–∏ –≤ –≤–∏–¥–µ –º–∞—Å—Å–∏–≤–∞, –±–µ—Ä–µ–º –ø–µ—Ä–≤—ã–π —ç–ª–µ–º–µ–Ω—Ç
        if isinstance(data, list):
            if len(data) == 0:
                return jsonify({
                    'success': False,
                    'error': 'Empty array provided'
                }), 400
            token_json = data[0]
        else:
            token_json = data
        
        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ —Ç–æ–∫–µ–Ω–∞
        processed_token_data = process_token_data(token_json)
        
        # –î–µ–ª–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
        prediction_result = predict_token_success(processed_token_data)
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã
        signals = analyze_token_signals(processed_token_data)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å
        safety = check_token_safety(processed_token_data)
        
        # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—é
        recommendation = get_recommendation(prediction_result, signals, safety)
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        response = {
            'success': True,
            'token_symbol': processed_token_data.get('symbol', 'UNKNOWN'),
            'processed_data': processed_token_data,
            'prediction': prediction_result,
            'signals': signals,
            'safety': safety,
            'recommendation': recommendation,
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        logger.info(f"‚úÖ –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {processed_token_data.get('symbol', 'UNKNOWN')} -> {prediction_result['prediction']} ({prediction_result['probability_percent']}%)")
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ API: {e}")
        return jsonify({
            'success': False,
            'error': str(e),
            'error_type': type(e).__name__
        }), 500

@app.route('/predict-batch', methods=['POST'])
def predict_batch():
    """Endpoint –¥–ª—è –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö —Ç–æ–∫–µ–Ω–æ–≤"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    try:
        # –ü–æ–ª—É—á–∞–µ–º JSON –¥–∞–Ω–Ω—ã–µ
        if not request.is_json:
            return jsonify({
                'success': False,
                'error': 'Content-Type must be application/json'
            }), 400
        
        data = request.get_json()
        
        if not data:
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        # –î–æ–ª–∂–µ–Ω –±—ã—Ç—å –º–∞—Å—Å–∏–≤ —Ç–æ–∫–µ–Ω–æ–≤
        if not isinstance(data, list):
            return jsonify({
                'success': False,
                'error': 'Expected array of tokens'
            }), 400
        
        results = []
        
        for i, token_json in enumerate(data):
            try:
                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–æ–∫–µ–Ω
                processed_token_data = process_token_data(token_json)
                prediction_result = predict_token_success(processed_token_data)
                signals = analyze_token_signals(processed_token_data)
                safety = check_token_safety(processed_token_data)
                recommendation = get_recommendation(prediction_result, signals, safety)
                
                token_result = {
                    'index': i,
                    'success': True,
                    'token_symbol': processed_token_data.get('symbol', 'UNKNOWN'),
                    'prediction': prediction_result,
                    'signals': signals,
                    'safety': safety,
                    'recommendation': recommendation
                }
                
                results.append(token_result)
                
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ç–æ–∫–µ–Ω–∞ {i}: {e}")
                results.append({
                    'index': i,
                    'success': False,
                    'error': str(e),
                    'token_symbol': token_json.get('symbol', 'UNKNOWN')
                })
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        successful = sum(1 for r in results if r.get('success'))
        failed = len(results) - successful
        
        response = {
            'success': True,
            'total_tokens': len(data),
            'successful_predictions': successful,
            'failed_predictions': failed,
            'results': results,
            'timestamp': pd.Timestamp.now().isoformat()
        }
        
        logger.info(f"‚úÖ –ü–∞–∫–µ—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ: {successful}/{len(data)} —É—Å–ø–µ—à–Ω–æ")
        
        return jsonify(response)
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞–∫–µ—Ç–Ω–æ–≥–æ API: {e}")
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

@app.route('/health', methods=['GET'])
def health():
    """Health check –¥–ª—è Railway"""
    
    model_info = {}
    model_status = "not_loaded"
    
    if model_artifacts:
        model_status = "loaded"
        try:
            model_info = {
                'auc': model_artifacts['performance_metrics']['test_auc'],
                'f1': model_artifacts['performance_metrics']['test_f1'],
                'features_count': len(model_artifacts['feature_names'])
            }
        except Exception as e:
            model_status = "loaded_but_corrupted"
            model_info = {'error': str(e)}
    
    return jsonify({
        'status': 'healthy',
        'model_status': model_status,
        'model_loaded': model_artifacts is not None,
        'model_info': model_info,
        'debug_info': {
            'current_directory': os.getcwd(),
            'files_in_directory': os.listdir('.'),
            'python_version': f"{pd.__version__}",
            'pandas_version': f"{np.__version__}"
        },
        'timestamp': pd.Timestamp.now().isoformat()
    })

@app.route('/model-info', methods=['GET'])
def model_info():
    """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –º–æ–¥–µ–ª–∏"""
    
    if model_artifacts is None:
        return jsonify({
            'success': False,
            'error': 'Model not loaded'
        }), 500
    
    # –¢–æ–ø-10 –≤–∞–∂–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    top_features = model_artifacts['feature_importance'].head(10).to_dict('records')
    
    return jsonify({
        'success': True,
        'model_type': model_artifacts.get('model_type', 'Unknown'),
        'training_approach': model_artifacts.get('training_approach', 'Unknown'),
        'performance_metrics': model_artifacts['performance_metrics'],
        'features_count': len(model_artifacts['feature_names']),
        'top_features': top_features,
        'all_features': model_artifacts['feature_names']
    })

@app.route('/reload-model', methods=['POST'])
def reload_model():
    """–ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
    
    logger.info("üîÑ –ü–æ–ø—ã—Ç–∫–∞ –ø–µ—Ä–µ–∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏...")
    
    model_loaded = load_model()
    
    if model_loaded:
        return jsonify({
            'success': True,
            'message': 'Model reloaded successfully',
            'model_info': {
                'auc': model_artifacts['performance_metrics']['test_auc'],
                'f1': model_artifacts['performance_metrics']['test_f1'],
                'features_count': len(model_artifacts['feature_names'])
            }
        })
    else:
        return jsonify({
            'success': False,
            'error': 'Failed to reload model',
            'debug_info': {
                'current_directory': os.getcwd(),
                'files_in_directory': os.listdir('.')
            }
        }), 500
def example():
    """–ü—Ä–∏–º–µ—Ä –≤—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–º JSON —Ñ–æ—Ä–º–∞—Ç–µ"""
    
    example_data = {
        "symbol": "CRUMB",
        "name": "Crumbcat",
        "contract_address": "Hz7MeU72BNF9rCWyUFAwKTyCcjr6qsJm1jwYehnqjups",
        "token_age": "2m",
        "views": 59,
        "market_cap": "129.1K",
        "liquidity": "47.3K",
        "sol_pooled": None,
        "ath": "152.7K",
        "ath_change_percent": -21,
        "ath_time_ago": "32s",
        "volume_1m": 148947.33,
        "buy_volume_1m": 81396.06,
        "sell_volume_1m": 67551.28,
        "buys_1m": 567,
        "sells_1m": 453,
        "volume_5m": 172794.94,
        "buy_volume_5m": 98494.49,
        "sell_volume_5m": 74300.45,
        "buys_5m": 670,
        "sells_5m": 517,
        "first_buyers": {
            "green": 14,
            "blue": 2,
            "yellow": 27,
            "red": 27,
            "clown": 0,
            "sun": 0,
            "moon_half": 0,
            "moon_new": 0
        },
        "current_initial_ratio": {
            "current": 23.8,
            "initial": 72.58
        },
        "total_holders": 383,
        "freshies_1d_percent": 5.5,
        "freshies_7d_percent": 18,
        "top_10_percent": 21,
        "top_10_holdings": [29.2, 3.38, 3.32, 2.96, 2.95, 2.56, 2.49, 2.26, 1.95, 1.89],
        "dev_current_balance_percent": 0,
        "dev_sol_balance": 0.225,
        "security": {
            "no_mint": True,
            "blacklist": True,
            "burnt": True,
            "dev_sold": True,
            "dex_paid": False
        }
    }
    
    return jsonify({
        'single_token_request': {
            'url': request.base_url.replace('/example', '/predict'),
            'method': 'POST',
            'headers': {
                'Content-Type': 'application/json'
            },
            'body': example_data
        },
        'array_request': {
            'url': request.base_url.replace('/example', '/predict'),
            'method': 'POST',
            'headers': {
                'Content-Type': 'application/json'
            },
            'body': [example_data]
        },
        'batch_request': {
            'url': request.base_url.replace('/example', '/predict-batch'),
            'method': 'POST',
            'headers': {
                'Content-Type': 'application/json'
            },
            'body': [example_data, example_data]
        }
    })

# –û–±—Ä–∞–±–æ—Ç–∫–∞ –æ—à–∏–±–æ–∫
@app.errorhandler(404)
def not_found(error):
    return jsonify({
        'success': False,
        'error': 'Endpoint not found',
        'available_endpoints': ['/predict', '/predict-batch', '/health', '/model-info', '/example']
    }), 404

@app.errorhandler(500)
def internal_error(error):
    return jsonify({
        'success': False,
        'error': 'Internal server error'
    }), 500

# –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
if __name__ == '__main__':
    # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ
    logger.info("üöÄ –ó–∞–ø—É—Å–∫ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è...")
    model_loaded = load_model()
    
    if model_loaded:
        logger.info("‚úÖ –ú–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, API –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    else:
        logger.warning("‚ö†Ô∏è –ú–æ–¥–µ–ª—å –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞, –Ω–æ API –∑–∞–ø—É—Å—Ç–∏—Ç—Å—è –≤ —Ä–µ–∂–∏–º–µ –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏")
    
    # –ü–æ–ª—É—á–∞–µ–º –ø–æ—Ä—Ç –∏–∑ –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π –æ–∫—Ä—É–∂–µ–Ω–∏—è (Railway)
    port = int(os.environ.get('PORT', 5000))
    
    # –ó–∞–ø—É—Å–∫–∞–µ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ
    app.run(host='0.0.0.0', port=port, debug=False)
